{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d015152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bussilab\n",
    "import scipy\n",
    "from scipy.optimize import minimize\n",
    "import cudamat as cm\n",
    "import numpy as np\n",
    "np.random.seed(1995)\n",
    "import os\n",
    "curr_dir=os.getcwd()\n",
    "import gc\n",
    "\n",
    "from random import choices\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cadbf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Tools to perform reweighting using MaxEnt.\n",
    "\"\"\"\n",
    "import sys\n",
    "from typing import Optional, Callable\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from bussilab import coretools\n",
    "\n",
    "try:\n",
    "    import cudamat as cm  # pylint: disable=import-error\n",
    "    _HAS_CUDAMAT=True\n",
    "except ModuleNotFoundError:\n",
    "    _HAS_CUDAMAT=False\n",
    "\n",
    "\n",
    "class MaxentResult(coretools.Result):\n",
    "    \"\"\"Result of a `bussilab.maxent.maxent` calculation.\"\"\"\n",
    "    def __init__(self,\n",
    "                 *,\n",
    "                 logW_ME: np.ndarray,\n",
    "                 lambdas: np.ndarray,\n",
    "                 averages: np.ndarray,\n",
    "                 gamma: float,\n",
    "                 success: bool,\n",
    "                 message: str,\n",
    "                 nfev: int,\n",
    "                 nit: int):\n",
    "        super().__init__()\n",
    "        self.logW_ME = logW_ME\n",
    "        \"\"\"`np.ndarray` with `traj.shape[0]` elements, logarithms of the optimized weights.\"\"\"\n",
    "        self.lambdas = lambdas\n",
    "        \"\"\"`np.ndarray` with `len(reference)` elements, optimized Lagrangian multipliers.\"\"\"\n",
    "        self.averages = averages\n",
    "        \"\"\"`np.ndarray` with `len(reference)` elements, resulting averages.\"\"\"\n",
    "        self.gamma = gamma\n",
    "        \"\"\"`float` containing the resulting likelihood Gamma.\"\"\"\n",
    "        self.success = success\n",
    "        \"\"\"`bool` reporting the success of the minimizer.\"\"\"\n",
    "        self.message = message\n",
    "        \"\"\"`str` reporting the possible reason of failuer of the minimizer.\"\"\"\n",
    "        self.nfev = nfev\n",
    "        \"\"\"`int` reporting the number of function evaluations.\"\"\"\n",
    "        self.nit = nit\n",
    "        \"\"\"`int` reporting the number of iterations in the minimization procedure.\"\"\"\n",
    "\n",
    "# Internal tool\n",
    "# should be called before sum() calls in cudamat\n",
    "def _ensure_ones(min_size):\n",
    "    if cm.CUDAMatrix.ones.shape[0]<min_size:\n",
    "        cm.CUDAMatrix.ones = cm.empty((min_size, 1)).assign(1.0)\n",
    "\n",
    "def _ensure_cm_init():\n",
    "    if not hasattr(cm.CUDAMatrix, 'ones'):\n",
    "        cm.cublas_init()\n",
    "    elif not isinstance(cm.CUDAMatrix.ones,cm.CUDAMatrix):\n",
    "        cm.cublas_init()\n",
    "\n",
    "# Internal tool to compute averages over trajectory.\n",
    "# Does not access external data.\n",
    "# Might be optimized on GPU or to access traj from disk.\n",
    "def _heavy_part(logW: np.ndarray,\n",
    "                traj: np.ndarray,\n",
    "                l: np.ndarray,\n",
    "                weights: bool = False,\n",
    "                cuda: bool = False):\n",
    "    if cuda:\n",
    "        cu_minus_l=cm.CUDAMatrix(np.reshape(-l,(-1,1)))\n",
    "        logW_ME = cm.dot(traj,cu_minus_l)\n",
    "        logW_ME.add(logW)\n",
    "        shift_ME = logW_ME.max(0).asarray()[0,0]\n",
    "        logW_ME.subtract(float(shift_ME))\n",
    "        if weights:\n",
    "            save_logW_ME=logW_ME.copy()\n",
    "        cm.exp(logW_ME)\n",
    "        _ensure_ones(logW_ME.shape[0])\n",
    "        Z=logW_ME.sum(0).asarray()[0,0]\n",
    "        averages = cm.dot(logW_ME.transpose(),traj).asarray()[0,:]\n",
    "        averages=np.array(averages,dtype=\"float64\")/Z\n",
    "        logZ = np.log(Z) + shift_ME\n",
    "        if not weights:\n",
    "            return (logZ, averages)\n",
    "        save_logW_ME.subtract(float(np.log(Z)))\n",
    "        return (logZ, averages, save_logW_ME.asarray()[:,0])\n",
    "    else:\n",
    "        logW_ME = logW-np.dot(traj, l)  # maxent correction\n",
    "        shift_ME = np.max(logW_ME)  # shift to avoid overflow\n",
    "        W_ME = np.exp(logW_ME - shift_ME)\n",
    "        # Partition function:\n",
    "        Z = np.sum(W_ME)\n",
    "        # Averages:\n",
    "        averages = np.dot(W_ME, traj) / Z\n",
    "        logZ = np.log(Z) + shift_ME\n",
    "        if not weights:\n",
    "            return (logZ, averages)\n",
    "        # only return weights if requested:\n",
    "        logW_ME -= np.log(Z)+shift_ME\n",
    "        return (logZ, averages, logW_ME)\n",
    "\n",
    "\n",
    "def maxent(\n",
    "        traj,\n",
    "        reference,\n",
    "        *,\n",
    "        logW=None,\n",
    "        maxiter: int = 1000,\n",
    "        verbose: bool =False,\n",
    "        lambdas=None,\n",
    "        l2=None,\n",
    "        l1=None,\n",
    "        method: str = \"L-BFGS-B\",\n",
    "        regularization: Optional[Callable] = None,\n",
    "        tol: Optional[float] = None,\n",
    "        options=None,\n",
    "        cuda=False):\n",
    "    \"\"\"Tool that computes new weights to enforce reference values.\n",
    "\n",
    "       This tools process a an array containing the observables computed along a trajectory and\n",
    "       returns new weights that satisfy the maximum entropy principle and so that weighted averages\n",
    "       agree with reference values.\n",
    "\n",
    "       Parameters\n",
    "       ----------\n",
    "\n",
    "       traj : array_like\n",
    "           A 2D array (lists or tuples are internally converted to numpy arrays).\n",
    "           `traj[i,j]` is j-th observable computed in the i-th frame.\n",
    "           If traj is a CUDAMatrix object, then cudamat is used irrespectively of the\n",
    "           bool parameter `cuda`.\n",
    "\n",
    "       reference : array_like\n",
    "\n",
    "           A 1D array (lists or tuples are internally converted to numpy arrays)\n",
    "           containing the reference values to be enforced. If the i-th element is a tuple\n",
    "           or an array with 2 elements, they are interpreted as boundaries. For instance,\n",
    "           `reference=[1.0,(2.0,3.0)]` will make sure the first observable has value 1 and\n",
    "           the second observable is within the range (2,3). Boundaries equal to `+np.inf`\n",
    "           or `-np.inf` can be used to imply no boundary. Notice that boundaries in the\n",
    "           form (A,B) where both A and B are finite are implemented by adding fictitious\n",
    "           variables in a way that is transparent to the user.  Boundaries in the form\n",
    "           (A,B) where one of A or B is finite and the other is infinite are implemented\n",
    "           as boundaries on lambdas.  Boundaries in the form (A,A) are interpreted as\n",
    "           constraints.\n",
    "\n",
    "       logW : array_like\n",
    "\n",
    "           A 1D array (lists or tuples are internally converted to numpy arrays)\n",
    "           containing the logarithm of the a priori weight of the provided frames.\n",
    "\n",
    "       lamdbas : array_like\n",
    "\n",
    "           A 1D array with initial values of lambda. A good guess will minimize faster. A\n",
    "           typical case would be recycling the lambdas obtained with slighlty different\n",
    "           regularization parameters.\n",
    "\n",
    "       l2 : None, float, or array_like\n",
    "\n",
    "           Prefactor for L2 regularization. If None, no regularization is applied. If\n",
    "           float, the same factor is used on all the lambdas.  If it is an array, it\n",
    "           should have length equal to `len(reference)`.\n",
    "\n",
    "       l1 : None, float, or array_like\n",
    "\n",
    "           Prefactor for L1 regularization. If None, no regularization is applied. If\n",
    "           float, the same factor is used on all the lambdas.  If it is an array, it\n",
    "           should have length equal to `len(reference)`.\n",
    "\n",
    "       regularization : callable or None\n",
    "\n",
    "           A function that takes as argument the current lambdas and return an tuple\n",
    "           containing the regularization function and its derivatives. For instance,\n",
    "           passing a function defined as\n",
    "           `def reg(x): return (0.0001*0.5*np.sum(x**2),0.0001*x)`\n",
    "           is equivalent to passing `l2=0.0001`.\n",
    "\n",
    "       verbose : bool\n",
    "           If True, progress informations are written on stdout.\n",
    "\n",
    "       method : str\n",
    "           Minimization method. See documentation of `scipy.optimize.minimize`.\n",
    "\n",
    "       maxiter : int\n",
    "           Maximum number of iterations\n",
    "\n",
    "       tol : float or None\n",
    "           Tolerance for minimization. See documentation of scipy.optimize.minimize.\n",
    "\n",
    "       options : dict\n",
    "           Arbitrary options passed to `scipy.optimize.minimize`.\n",
    "\n",
    "       cuda : bool or None (default False)\n",
    "           Use cuda. If None, chosen based on the availability of the cudamat library.\n",
    "\n",
    "       Notes on using CUDA\n",
    "       -------------------\n",
    "\n",
    "       Note that for normal datasets the cost of transfering the traj object to\n",
    "       the GPU dominates. It it however possible to transfer the traj object first to the GPU\n",
    "       with `cu_traj=cm.CUDAMatrix(traj)` and then reuse it for multiple calls\n",
    "       (e.g. for a hyper parameter scan).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if cuda is None:\n",
    "        cuda = _HAS_CUDAMAT\n",
    "\n",
    "    # when a cudamatrix is passed, cuda is enabled by default\n",
    "    if _HAS_CUDAMAT:\n",
    "        if isinstance(traj,cm.CUDAMatrix):\n",
    "            cuda=True\n",
    "\n",
    "    if cuda:\n",
    "        if not _HAS_CUDAMAT:\n",
    "            raise ValueError(\"Cudamat not available, can only run ANN with numpy\")\n",
    "        _ensure_cm_init()\n",
    "        if isinstance(traj,cm.CUDAMatrix):\n",
    "            cu_traj=traj\n",
    "        else:\n",
    "            traj = coretools.ensure_np_array(traj)\n",
    "            cu_traj=cm.CUDAMatrix(traj)\n",
    "    else:\n",
    "        traj = coretools.ensure_np_array(traj)\n",
    "\n",
    "    lambdas = coretools.ensure_np_array(lambdas)\n",
    "\n",
    "    nframes = traj.shape[0]\n",
    "    nobs = traj.shape[1]\n",
    "\n",
    "    # accepts a scalar as l2 regularization term\n",
    "    if isinstance(l2, float):\n",
    "        l2 = np.ones(nobs)*l2\n",
    "\n",
    "    l2 = coretools.ensure_np_array(l2)\n",
    "\n",
    "    if isinstance(l1, float):\n",
    "        l1 = np.ones(nobs)*l1\n",
    "\n",
    "    l1 = coretools.ensure_np_array(l1)\n",
    "    # default values\n",
    "    if logW is None:\n",
    "        logW = np.zeros(nframes)\n",
    "    if lambdas is None:\n",
    "        lambdas = np.zeros(nobs)\n",
    "\n",
    "    # checks\n",
    "    assert len(reference) == nobs\n",
    "    assert len(logW) == nframes\n",
    "    assert len(lambdas) == nobs\n",
    "\n",
    "    fullreference = []\n",
    "    bounds = []\n",
    "    box_const = []\n",
    "    for i in range(nobs):\n",
    "        if hasattr(reference[i], \"__len__\"):\n",
    "            if len(reference[i]) > 1:\n",
    "                if len(reference[i]) > 2:\n",
    "                    raise TypeError(\"\")\n",
    "                if reference[i][0] > reference[i][1]:\n",
    "                    raise TypeError(\"\")\n",
    "                if reference[i][0] == reference[i][1]:\n",
    "                    fullreference.append(reference[i][0])\n",
    "                    bounds.append((-np.inf, +np.inf))\n",
    "                    box_const.append(False)\n",
    "                elif (np.isinf(reference[i][1]) and reference[i][1] > 0.0\n",
    "                      and not np.isinf(reference[i][0])):\n",
    "                    fullreference.append(reference[i][0])\n",
    "                    bounds.append((-np.inf, 0.0))\n",
    "                    box_const.append(False)\n",
    "                elif (np.isinf(reference[i][0]) and reference[i][0] < 0.0\n",
    "                      and not np.isinf(reference[i][1])):\n",
    "                    fullreference.append(reference[i][1])\n",
    "                    bounds.append((0.0, +np.inf))\n",
    "                    box_const.append(False)\n",
    "                elif not np.isinf(reference[i][0]) and not np.isinf(reference[i][1]):\n",
    "                    fullreference.append(reference[i][0])\n",
    "                    fullreference.append(reference[i][1])\n",
    "                    bounds.append((-np.inf, 0.0))\n",
    "                    bounds.append((0.0, +np.inf))\n",
    "                    box_const.append(True)\n",
    "                elif ((np.isinf(reference[i][0]) and reference[i][0] < 0.0)\n",
    "                      and (np.isinf(reference[i][1]) and reference[i][1] > 0.0)):\n",
    "                    fullreference.append(0.0)\n",
    "                    bounds.append((0.0, 0.0))\n",
    "                    box_const.append(False)\n",
    "                else:\n",
    "                    raise TypeError(\"\")\n",
    "            else:\n",
    "                fullreference.append(reference[i][0])\n",
    "                bounds.append((-np.inf, +np.inf))\n",
    "                box_const.append(False)\n",
    "        else:\n",
    "            fullreference.append(reference[i])\n",
    "            bounds.append((-np.inf, +np.inf))\n",
    "            box_const.append(False)\n",
    "\n",
    "\n",
    "    # to fix these, use np.asarray, only available in numpy 1.20.0\n",
    "    fullreference = np.array(fullreference)  # type: ignore\n",
    "    bounds = np.array(bounds)  # type: ignore\n",
    "    box_const = np.array(box_const)  # type: ignore\n",
    "\n",
    "    nit = 0\n",
    "    def _callback(par):\n",
    "        nonlocal nit  # needed to access outer scope\n",
    "        nit += 1\n",
    "        if verbose:\n",
    "            sys.stderr.write(\"MAXENT: iteration \"+str(nit)+\"\\n\")\n",
    "\n",
    "    callback: Optional[Callable] = None\n",
    "    # verbose logging\n",
    "    if verbose:\n",
    "        sys.stderr.write(\"MAXENT: start\\n\")\n",
    "        callback = _callback\n",
    "\n",
    "    # logZ0 is not changing during minimization and is computed once.\n",
    "    # it is only needed to compute Gamma\n",
    "    shift0 = np.max(logW)  # shift to avoid overflow\n",
    "    W0 = np.exp(logW - shift0)\n",
    "    logZ0 = np.log(np.sum(W0)) + shift0\n",
    "\n",
    "    if cuda:\n",
    "        cu_logW=cm.CUDAMatrix(np.reshape(logW,(-1,1)))\n",
    "\n",
    "    # function to be minimized\n",
    "    def func(l):\n",
    "\n",
    "        l = np.array(l)  # ensure array\n",
    "\n",
    "        assert len(l) == len(fullreference)\n",
    "\n",
    "        # takes care of >< constraints\n",
    "        # vector ll only contains the Lagrangian multipliers to be applied on the trajectory\n",
    "        if len(fullreference) != nobs:\n",
    "            ll = np.zeros(nobs)\n",
    "            s = 0\n",
    "            for i in range(nobs):\n",
    "                if box_const[i]:\n",
    "                    # >< multipliers are summed\n",
    "                    ll[i] = l[i+s] + l[i+s+1]\n",
    "                    s += 1\n",
    "                else:\n",
    "                    ll[i] = l[i+s]\n",
    "        else:\n",
    "            ll = l\n",
    "\n",
    "\n",
    "        if cuda:\n",
    "            logZ, averages = _heavy_part(cu_logW, cu_traj, ll, cuda=cuda)\n",
    "        else:\n",
    "            logZ, averages = _heavy_part(logW, traj, ll, cuda=cuda)\n",
    "\n",
    "\n",
    "        f = logZ - logZ0\n",
    "        der = -averages\n",
    "\n",
    "\n",
    "        if regularization is not None:\n",
    "            reg = regularization(ll)\n",
    "            f += reg[0]\n",
    "            der += reg[1]\n",
    "\n",
    "        if l2 is not None:\n",
    "            f += 0.5*np.sum(l2*ll**2)\n",
    "            der += l2*ll\n",
    "\n",
    "        if l1 is not None:\n",
    "            eee = 1e-50\n",
    "            f += np.sum(l1*np.sqrt(ll**2+eee**2))\n",
    "            der += l1*ll/np.sqrt(ll**2+eee**2)\n",
    "\n",
    "        # takes care of >< constraints\n",
    "        # vector der only contains the nobs elements\n",
    "        # it is here extended\n",
    "        if len(fullreference) != nobs:\n",
    "            newder = np.zeros(len(fullreference))\n",
    "            s = 0\n",
    "            for i in range(nobs):\n",
    "                if box_const[i]:\n",
    "                    newder[i+s] = der[i]\n",
    "                    newder[i+s+1] = der[i]\n",
    "                    s += 1\n",
    "                else:\n",
    "                    newder[i+s] = der[i]\n",
    "            der = newder\n",
    "\n",
    "        # fullreference contains already nobs+nshift elements\n",
    "        f += np.dot(l, fullreference)\n",
    "        der += fullreference\n",
    "\n",
    "        return(f, der)\n",
    "\n",
    "\n",
    "    # With >< constraints the initial lambdas should be fixed\n",
    "    if len(fullreference) != nobs:\n",
    "        ll = np.zeros(len(fullreference))\n",
    "        s = 0\n",
    "        for i in range(nobs):\n",
    "            if box_const[i]:\n",
    "                if lambdas[i] >= 0:\n",
    "                    ll[i+s+1] = lambdas[i]\n",
    "                else:\n",
    "                    ll[i+s] = lambdas[i]\n",
    "                s += 1\n",
    "            else:\n",
    "                ll[i+s] = lambdas[i]\n",
    "        lambdas = ll\n",
    "\n",
    "    if maxiter is not None:\n",
    "        if options is None:\n",
    "            options = {}\n",
    "        options[\"maxiter\"] = maxiter\n",
    "\n",
    "    res = minimize(\n",
    "        func, lambdas, method=method, jac=True, callback=callback, bounds=bounds,\n",
    "        tol=tol, options=options)\n",
    "\n",
    "    # With >< constraints the final lambdas should be fixed\n",
    "    if len(fullreference) != nobs:\n",
    "        lambdas = np.zeros(nobs)\n",
    "        s = 0\n",
    "        for i in range(nobs):\n",
    "            if box_const[i]:\n",
    "                lambdas[i] = res.x[i+s]+res.x[i+s+1]\n",
    "                s += 1\n",
    "            else:\n",
    "                lambdas[i] = res.x[i+s]\n",
    "    else:\n",
    "        lambdas = res.x\n",
    "\n",
    "    # recompute weights at the end\n",
    "    if cuda:\n",
    "        logZ, averages, logW_ME = _heavy_part(cu_logW, cu_traj, lambdas, weights=True, cuda=cuda)\n",
    "    else:\n",
    "        logZ, averages, logW_ME = _heavy_part(logW, traj, lambdas, weights=True)\n",
    "\n",
    "    if verbose:\n",
    "        sys.stderr.write(\"MAXENT: end\\n\")\n",
    "\n",
    "    return MaxentResult(\n",
    "        logW_ME=logW_ME,\n",
    "        lambdas=lambdas,\n",
    "        averages=averages,\n",
    "        gamma=res.fun,\n",
    "        success=res.success,\n",
    "        message=res.message,\n",
    "        nfev=res.nfev,\n",
    "        nit=res.nit\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1070083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sequences=['AAAA','CAAU','GACC','CCCC','UUUU','UCAAUC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faa21765",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instead of heavy atoms the hydrogens are used for dihedral angle computation in this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb45d789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _relu(x):\n",
    "    return np.maximum(x,0)\n",
    "\n",
    "def _drelu(x):\n",
    "    return np.heaviside(x,0.5)\n",
    "\n",
    "\n",
    "def func_grad(par,opt=True,regularize=True):\n",
    "    \n",
    "    func=0\n",
    "    grad=np.zeros(par.shape)\n",
    "    chi2_func=0\n",
    "    chi2_grad=np.zeros(par.shape)\n",
    "    gamma_func=0\n",
    "    gamma_grad=np.zeros(par.shape)\n",
    "    new_chi_list=[]\n",
    "    \n",
    "    new_weights_list=[]\n",
    "    new_lambdas_list=[]\n",
    "    \n",
    "    for s,Sequence in enumerate(Sequences):\n",
    "\n",
    "        gamma_jcoupl_components=func_grad.gamma_jcoupl_components_list[s][:,func_grad.selection_frames[:,np.newaxis],func_grad.selection_obs_gamma[s]]\n",
    "        beta_jcoupl_components=func_grad.beta_jcoupl_components_list[s][:,func_grad.selection_frames[:,np.newaxis],func_grad.selection_obs_beta[s]]\n",
    "        sugar_jcoupl_components=func_grad.sugar_jcoupl_components_list[s][:,func_grad.selection_frames[:,np.newaxis],func_grad.selection_obs_sugar[s]]\n",
    "\n",
    "        gamma_jcoupl_components/=func_grad.backbone1_exp_list[s][:,1][np.newaxis,func_grad.selection_obs_gamma[s]]\n",
    "        beta_jcoupl_components/=func_grad.backbone2_exp_list[s][:,1][np.newaxis,func_grad.selection_obs_beta[s]]\n",
    "        sugar_jcoupl_components/=func_grad.sugar_exp_list[s][:,1][np.newaxis,func_grad.selection_obs_sugar[s]]\n",
    "        \n",
    "        new_backbone1_coupl=np.einsum('i,ijk->jk',par[0:3],gamma_jcoupl_components)\n",
    "        new_backbone2_coupl=np.einsum('i,ijk->jk',par[3:6],beta_jcoupl_components)\n",
    "        new_sugar_coupl=np.einsum('i,ijk->jk',par[6:9],sugar_jcoupl_components)\n",
    "        \n",
    "        jscalar_couplings=np.hstack((new_backbone1_coupl,new_backbone2_coupl,new_sugar_coupl))\n",
    "        \n",
    "        noe=np.copy(func_grad.noe_list[s])[func_grad.selection_frames[:,np.newaxis],func_grad.selection_obs_noe[s]]/func_grad.noe_exp_list[s][:,1][np.newaxis,func_grad.selection_obs_noe[s]]\n",
    "        unoe=np.copy(func_grad.unoe_list[s])[func_grad.selection_frames[:,np.newaxis],func_grad.selection_obs_unoe[s]]/np.array(func_grad.unoe_exp_list[s][:,1],dtype=float)[np.newaxis,func_grad.selection_obs_unoe[s]]\n",
    "        \n",
    "        \n",
    "        simulations_data=np.hstack((jscalar_couplings,noe,unoe))\n",
    "        exp_data=func_grad.exp_data_list[s][func_grad.selection_obs[s]] \n",
    "        \n",
    "        m=maxent(simulations_data,exp_data,l2=func_grad.alpha, cuda=cuda)\n",
    "        new_lambdas_list.append(m.lambdas)\n",
    "\n",
    "        Gamma=m.gamma\n",
    "        new_weights=np.exp(m.logW_ME)\n",
    "        new_weights_list.append(new_weights) \n",
    "\n",
    "        gamma_func+=-func_grad.alpha*Gamma\n",
    "            \n",
    "        if opt==True:\n",
    "            \n",
    "            ave_der_backbone1=np.einsum('i,jik->jk',new_weights,gamma_jcoupl_components)\n",
    "            ave_der_backbone2=np.einsum('i,jik->jk',new_weights,beta_jcoupl_components)\n",
    "            ave_der_sugar=np.einsum('i,jik->jk',new_weights,sugar_jcoupl_components)\n",
    "\n",
    "            backbone1_lambdas=ave_der_backbone1.shape[1]\n",
    "            backbone2_lambdas=backbone1_lambdas+ave_der_backbone2.shape[1]\n",
    "            sugar_lambdas=backbone2_lambdas+ave_der_sugar.shape[1]\n",
    "            \n",
    "            temp_grad=[[],[],[]]\n",
    "            temp_grad[0]=np.einsum('i,ji->j',m.lambdas[0:backbone1_lambdas],ave_der_backbone1)\n",
    "            temp_grad[1]=np.einsum('i,ji->j',m.lambdas[backbone1_lambdas:backbone2_lambdas],ave_der_backbone2)\n",
    "            temp_grad[2]=np.einsum('i,ji->j',m.lambdas[backbone2_lambdas:sugar_lambdas],ave_der_sugar)\n",
    "\n",
    "            gamma_grad+=func_grad.alpha*np.array(temp_grad).flatten()\n",
    "            \n",
    "    \n",
    "    func+=gamma_func\n",
    "    grad+=gamma_grad\n",
    "\n",
    "    func/=len(Sequences) \n",
    "    grad/=len(Sequences) \n",
    "\n",
    "    #add regularization \n",
    "    if regularize ==True:\n",
    "        \n",
    "        if regularization=='L2':\n",
    "            func+=func_grad.hyperparameter*np.sum((par-Karplus_parameters_transformed)**2)\n",
    "            grad+=func_grad.hyperparameter*2*(par-Karplus_parameters_transformed)\n",
    "\n",
    "    if opt==True:\n",
    "        return func,grad\n",
    "\n",
    "    else:\n",
    "        return np.array(new_chi_list)/func_grad.M,new_weights_list,new_lambdas_list #,new_gamma_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d34bb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to load data successfully download files from https://zenodo.org/record/7746293\n",
    "#create a dir 'dataload'\n",
    "#create subdir for each system in ['AAAA','CAAU','GACC','CCCC','UUUU','UCAAUC']\n",
    "#place corresponding files into the respective subdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92084cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load experimental data\n",
    "M=0\n",
    "#we choose an assumed experimental error for jcoupling data:\n",
    "sigma_exp=0.3 \n",
    "def read_exp(path, columns):\n",
    "    matrix=[]\n",
    "    for col in range(columns):\n",
    "        matrix.append([])\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            if '#' not in line:\n",
    "                nums=line.split()\n",
    "                for col in range(columns):\n",
    "                    matrix[col].append(nums[col])\n",
    "    return np.array(matrix)\n",
    "\n",
    "func_grad.backbone1_exp_list=[]\n",
    "func_grad.backbone2_exp_list=[]\n",
    "func_grad.sugar_exp_list=[]\n",
    "\n",
    "func_grad.noe_exp_list=[]\n",
    "func_grad.unoe_exp_list=[]\n",
    "\n",
    "for s,Sequence in enumerate(Sequences):\n",
    "    print(Sequence)\n",
    "    j3_data=read_exp(curr_dir+'/dataload/%s/j3_%s.exp.dat' %(Sequence,Sequence),3 )\n",
    "    \n",
    "\n",
    "    backbone1_exp=[]\n",
    "    backbone2_exp=[]\n",
    "    sugar_exp=[]\n",
    "    for e,elem in enumerate(j3_data.T):\n",
    "        #print(elem[0])\n",
    "        if '1H5H4' in elem[0] or '2H5H4'in elem[0]:\n",
    "            backbone1_exp.append([float(elem[1]),float(sigma_exp)])\n",
    "        if '1H5P' in elem[0] or '2H5P' in elem[0] or 'H3P' in elem[0]:\n",
    "            backbone2_exp.append([float(elem[1]),float(sigma_exp)])\n",
    "        if 'H1H2'  in elem[0] or 'H2H3' in elem[0] or 'H3H4' in elem[0]:\n",
    "            sugar_exp.append([float(elem[1]),float(sigma_exp)])\n",
    "\n",
    "    backbone1_exp=np.array(backbone1_exp)\n",
    "    if 'CAAU' in Sequence:\n",
    "        backbone2_exp=np.array(backbone2_exp[:-1])\n",
    "    else:\n",
    "        backbone2_exp=np.array(backbone2_exp)\n",
    "    sugar_exp=np.array(sugar_exp)\n",
    "\n",
    "    print(backbone1_exp.shape)\n",
    "    print(backbone2_exp.shape)\n",
    "    print(sugar_exp.shape)\n",
    "    func_grad.backbone1_exp_list.append(backbone1_exp)\n",
    "    func_grad.backbone2_exp_list.append(backbone2_exp)\n",
    "    func_grad.sugar_exp_list.append(sugar_exp)\n",
    "    \n",
    "    #NOE and uNOE\n",
    "    if Sequence!='UCAAUC':\n",
    "        if Sequence=='CAAU':\n",
    "            unoe_data=read_exp(curr_dir+'/dataload/%s/formatted_unoe_%s.exp.dat' %(Sequence,Sequence),4 )\n",
    "        else:\n",
    "            unoe_data=read_exp(curr_dir+'/dataload/%s/unoe_%s.exp.dat' %(Sequence,Sequence),4 )\n",
    "        noe_data=read_exp(curr_dir+'/dataload/%s/noe_%s.exp.dat' %(Sequence,Sequence),5 )\n",
    "\n",
    "        noe_exp=noe_data.T[:,2:]\n",
    "        unoe_exp=unoe_data.T[:,2:]\n",
    "        noe_exp=noe_exp[:,:].astype(float)\n",
    "\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        noe_data=read_exp(curr_dir+'/dataload/%s/formatted_noe_%s.exp.dat' %(Sequence,Sequence),5 )\n",
    "        unoe_data=read_exp(curr_dir+'/dataload/%s/formatted_unoe_%s.exp.dat' %(Sequence,Sequence),4 )\n",
    "        #special noe treatment, because the experimental data required summing some signals\n",
    "        lines_to_ignore=[2, 4, 6, 8, 10, 12, 14, 16, 19, 26, 29, 32, 39]\n",
    "\n",
    "        for index in sorted(lines_to_ignore, reverse=True):\n",
    "            noe_data=np.delete(noe_data,index,1)\n",
    "        \n",
    "        noe_exp=noe_data.T[:,2:]\n",
    "        unoe_exp=unoe_data.T[:,2:]\n",
    "        noe_exp=noe_exp[:,:].astype(float)\n",
    "        \n",
    "    temp=[]\n",
    "    for i in range(noe_exp.shape[0]):\n",
    "        temp.append([noe_exp[i,1],np.min([noe_exp[i,2]-noe_exp[i,1],noe_exp[i,1]-noe_exp[i,0]])])\n",
    "    noe_exp=np.array(temp)\n",
    "    unoe_exp=unoe_exp[:,:].astype(float)\n",
    "\n",
    "    print(noe_exp.shape)\n",
    "    print(unoe_exp.shape)\n",
    "\n",
    "    func_grad.noe_exp_list.append(noe_exp)\n",
    "    \n",
    "    #change to NOE signal\n",
    "    noe_exp=np.copy(func_grad.noe_exp_list[s])\n",
    "    \n",
    "    exp_noe=noe_exp[:,0]**(-6)\n",
    "    a=np.abs((noe_exp[:,0]-noe_exp[:,1])**(-6)-noe_exp[:,0]**(-6))\n",
    "    b=np.abs((noe_exp[:,0]+noe_exp[:,1])**(-6)-noe_exp[:,0]**(-6))\n",
    "    exp_noe_std=(a+b)/2\n",
    "    \n",
    "    func_grad.noe_exp_list[s][:,0]=exp_noe\n",
    "    func_grad.noe_exp_list[s][:,1]=exp_noe_std\n",
    "    \n",
    "    temp=[]\n",
    "    for e,elem in enumerate(unoe_exp):\n",
    "        temp.append([(unoe_exp[e][0],+np.inf),unoe_exp[e][1]])\n",
    "\n",
    "    unoe_exp=np.array(temp,dtype='object')\n",
    "    func_grad.unoe_exp_list.append(unoe_exp)\n",
    "    \n",
    "    #change to NOE signal\n",
    "    unoe_exp_temp=np.copy(unoe_exp)\n",
    "    \n",
    "    exp_unoe=[]\n",
    "    exp_unoe_std=[]\n",
    "    for e,elem in enumerate(unoe_exp[:,0]):\n",
    "        func_grad.unoe_exp_list[s][e,0]=(0,unoe_exp_temp[e,0][0]**(-6))\n",
    "        func_grad.unoe_exp_list[s][e,1]=np.abs((unoe_exp_temp[e,0][0]-unoe_exp_temp[e,1])**(-6)-unoe_exp_temp[e,0][0]**(-6))\n",
    "    \n",
    "    \n",
    "    M+=backbone1_exp.shape[0]+backbone2_exp.shape[0]+sugar_exp.shape[0]+noe_exp.shape[0]+unoe_exp.shape[0]\n",
    "print('number of experiments: ',M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fc2ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Karplus parameters contains A,B and C for gamma, beta and sugar in this order\n",
    "Karplus_parameters=np.array([[9.7,-1.8,0],[15.3,-6.1,1.6],[9.67,-2.03,0]])\n",
    "\n",
    "def transform_Karplus(par):\n",
    "    new_par=[]\n",
    "    for elem in par:\n",
    "        A=elem[0]\n",
    "        B=elem[1]\n",
    "        C=elem[2]\n",
    "\n",
    "        A_T=A/2\n",
    "        B_T=B\n",
    "        C_T=np.sqrt(2)*(C+A/2)\n",
    "        new_par.append([A_T,B_T,C_T])\n",
    "    return np.array(new_par).flatten(),par.flatten()\n",
    "\n",
    "Karplus_parameters_transformed,Karplus_parameters=transform_Karplus(Karplus_parameters)\n",
    "\n",
    "func_grad.gamma_jcoupl_components_list=[]\n",
    "func_grad.beta_jcoupl_components_list=[]\n",
    "func_grad.sugar_jcoupl_components_list=[]\n",
    "func_grad.noe_list=[]\n",
    "func_grad.unoe_list=[]\n",
    "\n",
    "\n",
    "for s,Sequence in enumerate(Sequences):\n",
    "    print(Sequence)\n",
    "    gamma_angle=np.load(curr_dir+'/dataload/%s/MaxEnt_gamma_angle_%s_300K.npy' %(Sequence,Sequence))\n",
    "    beta_angle=np.load(curr_dir+'/dataload/%s/MaxEnt_beta_angle_%s_300K.npy' %(Sequence,Sequence))\n",
    "    sugar_angle=np.load(curr_dir+'/dataload/%s/MaxEnt_sugar_angle_%s_300K.npy' %(Sequence,Sequence))\n",
    "    \n",
    "    gamma_angle=gamma_angle[:int(1e6)]\n",
    "    beta_angle=beta_angle[:int(1e6)]\n",
    "    sugar_angle=sugar_angle[:int(1e6)]\n",
    "    \n",
    "    gamma_jcoupl_components=np.array([np.cos(2*gamma_angle),np.cos(gamma_angle),np.ones(gamma_angle.shape)/np.sqrt(2)])\n",
    "    beta_jcoupl_components=np.array([np.cos(2*beta_angle),np.cos(beta_angle),np.ones(beta_angle.shape)/np.sqrt(2)])\n",
    "    sugar_jcoupl_components=np.array([np.cos(2*sugar_angle),np.cos(sugar_angle),np.ones(sugar_angle.shape)/np.sqrt(2)])\n",
    "    \n",
    "    backbone1_coupl=np.einsum('i,ijk->jk',Karplus_parameters_transformed[0:3],gamma_jcoupl_components)\n",
    "    backbone2_coupl=np.einsum('i,ijk->jk',Karplus_parameters_transformed[3:6],beta_jcoupl_components)\n",
    "    sugar_coupl=np.einsum('i,ijk->jk',Karplus_parameters_transformed[6:9],sugar_jcoupl_components)\n",
    "\n",
    "    \n",
    "    #NOEs\n",
    "    noe = np.load(curr_dir+\"/dataload/%s/noe6m_%s_300K.npy\" %(Sequence,Sequence))\n",
    "    unoe = np.load(curr_dir+\"/dataload/%s/unoe6m_%s_300K.npy\" %(Sequence,Sequence))\n",
    "\n",
    "    noe=noe.reshape(-1,noe.shape[1])\n",
    "    unoe=unoe.reshape(-1,unoe.shape[1])\n",
    "    noe=noe[:int(1e6),:]\n",
    "    unoe=unoe[:int(1e6),:]\n",
    "    \n",
    "    \n",
    "    skip=100\n",
    "    prune=False\n",
    "    if prune==True:\n",
    "        gamma_angle=gamma_angle[::skip,:]\n",
    "        beta_angle=beta_angle[::skip,:]\n",
    "        sugar_angle=sugar_angle[::skip,:]\n",
    "        gamma_jcoupl_components=gamma_jcoupl_components[:,::skip,:]\n",
    "        beta_jcoupl_components=beta_jcoupl_components[:,::skip,:]\n",
    "        sugar_jcoupl_components=sugar_jcoupl_components[:,::skip,:]\n",
    "        noe=noe[::skip,:]\n",
    "        unoe=unoe[::skip,:]\n",
    "        \n",
    "        gc.collect()\n",
    "        \n",
    "    print(gamma_angle.shape)\n",
    "    print(beta_angle.shape)\n",
    "    print(sugar_angle.shape)\n",
    "    print(gamma_jcoupl_components.shape)\n",
    "    print(beta_jcoupl_components.shape)\n",
    "    print(sugar_jcoupl_components.shape)\n",
    "    \n",
    "    print(noe.shape)\n",
    "    print(unoe.shape)\n",
    "\n",
    "    \n",
    "    func_grad.gamma_jcoupl_components_list.append(gamma_jcoupl_components)\n",
    "    func_grad.beta_jcoupl_components_list.append(beta_jcoupl_components)\n",
    "    func_grad.sugar_jcoupl_components_list.append(sugar_jcoupl_components)\n",
    "    func_grad.noe_list.append(noe)\n",
    "    func_grad.unoe_list.append(unoe)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bffd8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove 20% of all the NOE observables are excluded to be used as a 'true' validation\n",
    "\n",
    "#the files needed for CV analysis can be found in 'CV_files'\n",
    "#also thos, place them in your 'dataload' dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b153fa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#when training\n",
    "training_set_selection=np.load(curr_dir+'/dataload/CV207030_training_set_selection_300K.npy')\n",
    "\n",
    "#when validating the new Karplus parameters\n",
    "#true_validation_selection=np.load('curr_dir+'/dataload/CV207030_true_validation_selection_300K.npy')\n",
    "\n",
    "def true_validation_selector(obs,sel,shape_ndx):\n",
    "    applied_selection=sel[sel<obs.shape[shape_ndx]]\n",
    "    sel-=obs.shape[shape_ndx]\n",
    "    sel=sel[sel >= 0]\n",
    "    \n",
    "    return sel,np.array(applied_selection,dtype=np.int) \n",
    "\n",
    "temp_sel_exp=np.copy(training_set_selection)\n",
    "temp_sel_sim=np.copy(training_set_selection)\n",
    "for s,Sequence in enumerate(Sequences):\n",
    "    \n",
    "    #experiments\n",
    "    temp_sel_exp,applied_selection=true_validation_selector(func_grad.noe_exp_list[s],temp_sel_exp,0)\n",
    "    func_grad.noe_exp_list[s]=func_grad.noe_exp_list[s][applied_selection]\n",
    "    temp_sel_exp,applied_selection=true_validation_selector(func_grad.unoe_exp_list[s],temp_sel_exp,0)\n",
    "    func_grad.unoe_exp_list[s]=func_grad.unoe_exp_list[s][applied_selection]\n",
    "    #simulation data\n",
    "    \n",
    "    temp_sel_sim,applied_selection=true_validation_selector(func_grad.noe_list[s],temp_sel_sim,1)\n",
    "    func_grad.noe_list[s]=func_grad.noe_list[s][:,applied_selection]\n",
    "    temp_sel_sim,applied_selection=true_validation_selector(func_grad.unoe_list[s],temp_sel_sim,1)\n",
    "    func_grad.unoe_list[s]=func_grad.unoe_list[s][:,applied_selection]\n",
    "    \n",
    "    print(func_grad.noe_exp_list[s].shape)\n",
    "    print(func_grad.unoe_exp_list[s].shape)\n",
    "    print(func_grad.noe_list[s].shape)\n",
    "    print(func_grad.unoe_list[s].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_grad.exp_jscalar_couplings_list=[]\n",
    "func_grad.exp_data_list=[]\n",
    "\n",
    "func_grad.M=0\n",
    "for s,Sequence in enumerate(Sequences):\n",
    "    \n",
    "    exp_jscalar_couplings=np.vstack((func_grad.backbone1_exp_list[s],func_grad.backbone2_exp_list[s],func_grad.sugar_exp_list[s]))\n",
    "    exp_data=np.vstack((exp_jscalar_couplings,func_grad.noe_exp_list[s],func_grad.unoe_exp_list[s]))\n",
    "    \n",
    "    scal_rng=exp_jscalar_couplings.shape[0]\n",
    "    noe_rng=scal_rng+func_grad.noe_exp_list[s].shape[0]\n",
    "    scalar_coupl_temp=exp_data[:scal_rng,0]/exp_data[:scal_rng,1]\n",
    "    noe_temp=exp_data[scal_rng:noe_rng,0]/exp_data[scal_rng:noe_rng,1]\n",
    "    unoe_temp=[]\n",
    "    for elem in exp_data[noe_rng:]:\n",
    "        unoe_temp.append((elem[0][0],elem[0][1]/elem[1]))\n",
    "    print(len(unoe_temp))\n",
    "    for e,elem in enumerate(exp_data):\n",
    "        if e < scal_rng:\n",
    "            exp_data[e]=[scalar_coupl_temp[e],exp_data[e][1]]\n",
    "        if e >= scal_rng and e < noe_rng:\n",
    "            ndx=e-scal_rng\n",
    "            exp_data[e]=[noe_temp[ndx],exp_data[ndx][1]]\n",
    "        if e >= noe_rng:\n",
    "            ndx=e-noe_rng\n",
    "            exp_data[e]=[unoe_temp[ndx],exp_data[ndx][1]]\n",
    "    \n",
    "    exp_data=exp_data[:,0]\n",
    "    \n",
    "    print(exp_data.shape)\n",
    "    \n",
    "    func_grad.exp_jscalar_couplings_list.append(exp_jscalar_couplings)\n",
    "    func_grad.exp_data_list.append(exp_data)\n",
    "    \n",
    "    func_grad.M+=func_grad.exp_data_list[s].shape[0]\n",
    "print(func_grad.M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a5b02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weights(par,lambdas,training_frame_selection,validation_frame_selection,cuda):\n",
    "    \n",
    "    training_weights_list=[]\n",
    "    validation_weights_list1=[]\n",
    "    validation_weights_list2=[]\n",
    "    for s,Sequence in enumerate(Sequences):\n",
    "        gamma_jcoupl_components=func_grad.gamma_jcoupl_components_list[s][:,:,func_grad.selection_obs_gamma[s]]\n",
    "        beta_jcoupl_components=func_grad.beta_jcoupl_components_list[s][:,:,func_grad.selection_obs_beta[s]]\n",
    "        sugar_jcoupl_components=func_grad.sugar_jcoupl_components_list[s][:,:,func_grad.selection_obs_sugar[s]]\n",
    "\n",
    "        gamma_jcoupl_components/=func_grad.backbone1_exp_list[s][:,1][np.newaxis,func_grad.selection_obs_gamma[s]]\n",
    "        beta_jcoupl_components/=func_grad.backbone2_exp_list[s][:,1][np.newaxis,func_grad.selection_obs_beta[s]]\n",
    "        sugar_jcoupl_components/=func_grad.sugar_exp_list[s][:,1][np.newaxis,func_grad.selection_obs_sugar[s]]\n",
    "        \n",
    "        new_backbone1_coupl=np.einsum('i,ijk->jk',par[0:3],gamma_jcoupl_components)\n",
    "        new_backbone2_coupl=np.einsum('i,ijk->jk',par[3:6],beta_jcoupl_components)\n",
    "        new_sugar_coupl=np.einsum('i,ijk->jk',par[6:9],sugar_jcoupl_components)\n",
    "        \n",
    "        traj_jscalar=np.hstack((new_backbone1_coupl,new_backbone2_coupl,new_sugar_coupl))\n",
    "        \n",
    "        #add noes\n",
    "        noe=np.copy(func_grad.noe_list[s])[:,func_grad.selection_obs_noe[s]]/func_grad.noe_exp_list[s][:,1][np.newaxis,func_grad.selection_obs_noe[s]]\n",
    "        unoe=np.copy(func_grad.unoe_list[s])[:,func_grad.selection_obs_unoe[s]]/np.array(func_grad.unoe_exp_list[s][:,1],dtype=float)[np.newaxis,func_grad.selection_obs_unoe[s]]\n",
    "        \n",
    "        traj=np.hstack((traj_jscalar,noe,unoe))\n",
    "         \n",
    "        if cuda==True:\n",
    "            \n",
    "            cu_traj=cm.CUDAMatrix(traj)\n",
    "            \n",
    "            cu_minus_l=cm.CUDAMatrix(np.reshape(-lambdas[s],(-1,1)))\n",
    "            all_logW_ME = cm.dot(cu_traj,cu_minus_l).asarray()#[:,0]\n",
    "            \n",
    "            #obtain training weights\n",
    "            np_logW_ME=all_logW_ME[training_frame_selection]\n",
    "            logW_ME=cm.CUDAMatrix(np_logW_ME)\n",
    "            shift_ME = logW_ME.max(0).asarray()[0,0]\n",
    "            logW_ME.subtract(float(shift_ME))\n",
    "            save_logW_ME=logW_ME.copy()\n",
    "            cm.exp(logW_ME)\n",
    "            _ensure_ones(logW_ME.shape[0])\n",
    "            Z=logW_ME.sum(0).asarray()[0,0]\n",
    "            logZ = np.log(Z) + shift_ME\n",
    "            save_logW_ME.subtract(float(np.log(Z)))\n",
    "            w=np.exp(save_logW_ME.asarray()[:,0])\n",
    "            training_weights_list.append(w)\n",
    "            \n",
    "            #obtain validation weights 1 \n",
    "            np_logW_ME=all_logW_ME[validation_frame_selection]\n",
    "            logW_ME=cm.CUDAMatrix(np_logW_ME)\n",
    "            shift_ME = logW_ME.max(0).asarray()[0,0]\n",
    "            logW_ME.subtract(float(shift_ME))\n",
    "            save_logW_ME=logW_ME.copy()\n",
    "            cm.exp(logW_ME)\n",
    "            _ensure_ones(logW_ME.shape[0])\n",
    "            Z=logW_ME.sum(0).asarray()[0,0]\n",
    "            logZ = np.log(Z) + shift_ME\n",
    "            save_logW_ME.subtract(float(np.log(Z)))\n",
    "            w=np.exp(save_logW_ME.asarray()[:,0])\n",
    "            validation_weights_list1.append(w)\n",
    "            \n",
    "            #obtain validation weights 2 \n",
    "            np_logW_ME=all_logW_ME\n",
    "            logW_ME=cm.CUDAMatrix(np_logW_ME)\n",
    "            shift_ME = logW_ME.max(0).asarray()[0,0]\n",
    "            logW_ME.subtract(float(shift_ME))\n",
    "            save_logW_ME=logW_ME.copy()\n",
    "            cm.exp(logW_ME)\n",
    "            _ensure_ones(logW_ME.shape[0])\n",
    "            Z=logW_ME.sum(0).asarray()[0,0]\n",
    "            logZ = np.log(Z) + shift_ME\n",
    "            save_logW_ME.subtract(float(np.log(Z)))\n",
    "            w=np.exp(save_logW_ME.asarray()[:,0])\n",
    "            validation_weights_list2.append(w)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            all_logW_ME = -np.dot(traj, lambdas[s])  # maxent correction\n",
    "            \n",
    "            #obtain training weights\n",
    "            logW_ME=all_logW_ME[training_frame_selection]\n",
    "            shift_ME = np.max(logW_ME)  # shift to avoid overflow\n",
    "            W_ME = np.exp(logW_ME - shift_ME)\n",
    "            Z = np.sum(W_ME)\n",
    "            logZ = np.log(Z) + shift_ME\n",
    "            logW_ME -= np.log(Z)+shift_ME\n",
    "            w=np.exp(logW_ME)\n",
    "            training_weights_list.append(w)\n",
    "\n",
    "            #obtain validation weights 1 \n",
    "            logW_ME=all_logW_ME[validation_frame_selection]\n",
    "            shift_ME = np.max(logW_ME)  # shift to avoid overflow\n",
    "            W_ME = np.exp(logW_ME - shift_ME)\n",
    "            Z = np.sum(W_ME)\n",
    "            logZ = np.log(Z) + shift_ME\n",
    "            logW_ME -= np.log(Z)+shift_ME\n",
    "            w=np.exp(logW_ME)\n",
    "            validation_weights_list1.append(w)\n",
    "            \n",
    "            #obtain validation weights 2 \n",
    "            logW_ME=all_logW_ME\n",
    "            shift_ME = np.max(logW_ME)  # shift to avoid overflow\n",
    "            W_ME = np.exp(logW_ME - shift_ME)\n",
    "            Z = np.sum(W_ME)\n",
    "            logZ = np.log(Z) + shift_ME\n",
    "            logW_ME -= np.log(Z)+shift_ME\n",
    "            w=np.exp(logW_ME)\n",
    "            validation_weights_list2.append(w)\n",
    "        \n",
    "    return training_weights_list,validation_weights_list1,validation_weights_list2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7312d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_chi(par,weights_list):\n",
    "    \n",
    "    \n",
    "    chi2=0.0\n",
    "    chi2_sys_list=[]\n",
    "    \n",
    "    #simulation data should be recomputed using the new Karplus parameters and new weights from maxent\n",
    "    for s,Sequence in enumerate(Sequences):\n",
    "        \n",
    "        weights=weights_list[s]\n",
    "        \n",
    "        noe=func_grad.noe_list[s][func_grad.selection_frames[:,np.newaxis],func_grad.selection_obs_noe[s]]\n",
    "        unoe=func_grad.unoe_list[s][func_grad.selection_frames[:,np.newaxis],func_grad.selection_obs_unoe[s]]\n",
    "        \n",
    "        backbone1_exp=func_grad.backbone1_exp_list[s][func_grad.selection_obs_gamma[s]]\n",
    "        backbone2_exp=func_grad.backbone2_exp_list[s][func_grad.selection_obs_beta[s]]\n",
    "        sugar_exp=func_grad.sugar_exp_list[s][func_grad.selection_obs_sugar[s]]\n",
    "        noe_exp=func_grad.noe_exp_list[s][func_grad.selection_obs_noe[s]]\n",
    "        unoe_exp=func_grad.unoe_exp_list[s][func_grad.selection_obs_unoe[s]]\n",
    "\n",
    "        gamma_jcoupl_components=func_grad.gamma_jcoupl_components_list[s][:,func_grad.selection_frames[:,np.newaxis],func_grad.selection_obs_gamma[s]]\n",
    "        beta_jcoupl_components=func_grad.beta_jcoupl_components_list[s][:,func_grad.selection_frames[:,np.newaxis],func_grad.selection_obs_beta[s]]\n",
    "        sugar_jcoupl_components=func_grad.sugar_jcoupl_components_list[s][:,func_grad.selection_frames[:,np.newaxis],func_grad.selection_obs_sugar[s]]\n",
    "\n",
    "        new_backbone1_coupl=np.einsum('i,ijk->jk',par[0:3],gamma_jcoupl_components)\n",
    "        new_backbone2_coupl=np.einsum('i,ijk->jk',par[3:6],beta_jcoupl_components)\n",
    "        new_sugar_coupl=np.einsum('i,ijk->jk',par[6:9],sugar_jcoupl_components)\n",
    "        \n",
    "        pred=np.matmul(weights,new_backbone1_coupl)\n",
    "        chi2_backbone1=np.sum(((pred-backbone1_exp[:,0])/backbone1_exp[:,1])**2)\n",
    "        chi2+=chi2_backbone1\n",
    "        \n",
    "        pred=np.matmul(weights,new_backbone2_coupl)\n",
    "        chi2_backbone2=np.sum(((pred-backbone2_exp[:,0])/backbone2_exp[:,1])**2)\n",
    "        chi2+=chi2_backbone2\n",
    "        \n",
    "        pred=np.matmul(weights,new_sugar_coupl)\n",
    "        chi2_sugar=np.sum(((pred-sugar_exp[:,0])/sugar_exp[:,1])**2)\n",
    "        chi2+=chi2_sugar\n",
    "        \n",
    "        pred=np.matmul(weights,noe)\n",
    "        chi2_noe=np.sum(((pred-noe_exp[:,0])/noe_exp[:,1])**2)\n",
    "        chi2+=chi2_noe\n",
    "        \n",
    "        pred=np.matmul(weights,unoe)\n",
    "        chi2_unoe=0.0\n",
    "        for i in range(len(pred)):\n",
    "            diff=pred[i]-unoe_exp[i,0][1]\n",
    "            if(diff>.0):\n",
    "                chi2_unoe+=(diff/unoe_exp[i,1])**2\n",
    "        chi2+=chi2_unoe\n",
    "\n",
    "        chi2_sys_list.append([np.sum([chi2_backbone1,chi2_backbone2,chi2_sugar,chi2_noe,chi2_unoe])/func_grad.M,\n",
    "                                           chi2_backbone1/func_grad.M,chi2_backbone2/func_grad.M,chi2_sugar/func_grad.M,chi2_noe/func_grad.M,chi2_unoe/func_grad.M])\n",
    "        \n",
    "    chi2/=func_grad.M \n",
    "    chi2/=len(Sequences) \n",
    "\n",
    "    return chi2,chi2_sys_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b1af21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_chi_val(par,weights_list,weights_list2):\n",
    "    \n",
    "    \n",
    "    chi2=0.0\n",
    "    chi2_sys_list=[]\n",
    "    \n",
    "    #one time collect chi2 for validation on remaining frames of obs used in training\n",
    "    #the 2nd time collect chi2 on obs not used in training but all frames\n",
    "    for valtype in range(2):\n",
    "        \n",
    "        #simulation data should be recomputed using the new Karplus parameters and new weights from maxent\n",
    "        for s,Sequence in enumerate(Sequences):\n",
    "\n",
    "            if valtype == 0:\n",
    "                weights=weights_list[s]\n",
    "                noe=func_grad.noe_list[s][func_grad.selection_frames[:,np.newaxis],func_grad.selection_obs_noe1[s]]\n",
    "                unoe=func_grad.unoe_list[s][func_grad.selection_frames[:,np.newaxis],func_grad.selection_obs_unoe1[s]]\n",
    "\n",
    "                backbone1_exp=func_grad.backbone1_exp_list[s][func_grad.selection_obs_gamma1[s]]\n",
    "                backbone2_exp=func_grad.backbone2_exp_list[s][func_grad.selection_obs_beta1[s]]\n",
    "                sugar_exp=func_grad.sugar_exp_list[s][func_grad.selection_obs_sugar1[s]]\n",
    "                noe_exp=func_grad.noe_exp_list[s][func_grad.selection_obs_noe1[s]]\n",
    "                unoe_exp=func_grad.unoe_exp_list[s][func_grad.selection_obs_unoe1[s]]\n",
    "\n",
    "                gamma_jcoupl_components=func_grad.gamma_jcoupl_components_list[s][:,func_grad.selection_frames[:,np.newaxis],func_grad.selection_obs_gamma1[s]]\n",
    "                beta_jcoupl_components=func_grad.beta_jcoupl_components_list[s][:,func_grad.selection_frames[:,np.newaxis],func_grad.selection_obs_beta1[s]]\n",
    "                sugar_jcoupl_components=func_grad.sugar_jcoupl_components_list[s][:,func_grad.selection_frames[:,np.newaxis],func_grad.selection_obs_sugar1[s]]\n",
    "\n",
    "            if valtype == 1:\n",
    "                weights=weights_list2[s]\n",
    "            \n",
    "                noe=func_grad.noe_list[s][:,func_grad.selection_obs_noe2[s]]\n",
    "                unoe=func_grad.unoe_list[s][:,func_grad.selection_obs_unoe2[s]]\n",
    "\n",
    "                backbone1_exp=func_grad.backbone1_exp_list[s][func_grad.selection_obs_gamma2[s]]\n",
    "                backbone2_exp=func_grad.backbone2_exp_list[s][func_grad.selection_obs_beta2[s]]\n",
    "                sugar_exp=func_grad.sugar_exp_list[s][func_grad.selection_obs_sugar2[s]]\n",
    "                noe_exp=func_grad.noe_exp_list[s][func_grad.selection_obs_noe2[s]]\n",
    "                unoe_exp=func_grad.unoe_exp_list[s][func_grad.selection_obs_unoe2[s]]\n",
    "\n",
    "                gamma_jcoupl_components=func_grad.gamma_jcoupl_components_list[s][:,:,func_grad.selection_obs_gamma2[s]]\n",
    "                beta_jcoupl_components=func_grad.beta_jcoupl_components_list[s][:,:,func_grad.selection_obs_beta2[s]]\n",
    "                sugar_jcoupl_components=func_grad.sugar_jcoupl_components_list[s][:,:,func_grad.selection_obs_sugar2[s]]\n",
    "\n",
    "            new_backbone1_coupl=np.einsum('i,ijk->jk',par[0:3],gamma_jcoupl_components)\n",
    "            new_backbone2_coupl=np.einsum('i,ijk->jk',par[3:6],beta_jcoupl_components)\n",
    "            new_sugar_coupl=np.einsum('i,ijk->jk',par[6:9],sugar_jcoupl_components)\n",
    "\n",
    "            \n",
    "            pred=np.matmul(weights,new_backbone1_coupl)\n",
    "            chi2_backbone1=np.sum(((pred-backbone1_exp[:,0])/backbone1_exp[:,1])**2)\n",
    "            chi2+=chi2_backbone1\n",
    "\n",
    "            pred=np.matmul(weights,new_backbone2_coupl)\n",
    "            chi2_backbone2=np.sum(((pred-backbone2_exp[:,0])/backbone2_exp[:,1])**2)\n",
    "            chi2+=chi2_backbone2\n",
    "\n",
    "            pred=np.matmul(weights,new_sugar_coupl)\n",
    "            chi2_sugar=np.sum(((pred-sugar_exp[:,0])/sugar_exp[:,1])**2)\n",
    "            chi2+=chi2_sugar\n",
    "\n",
    "            pred=np.matmul(weights,noe)\n",
    "            chi2_noe=np.sum(((pred-noe_exp[:,0])/noe_exp[:,1])**2)\n",
    "            chi2+=chi2_noe\n",
    "\n",
    "            pred=np.matmul(weights,unoe)\n",
    "            chi2_unoe=0.0\n",
    "            for i in range(len(pred)):\n",
    "                diff=pred[i]-unoe_exp[i,0][1]\n",
    "                if(diff>.0):\n",
    "                    chi2_unoe+=(diff/unoe_exp[i,1])**2\n",
    "            chi2+=chi2_unoe\n",
    "        \n",
    "            if valtype == 0:\n",
    "                chi2_sys_list.append([np.sum([chi2_backbone1,chi2_backbone2,chi2_sugar,chi2_noe,chi2_unoe])/func_grad.M,\n",
    "                                               chi2_backbone1/func_grad.M,chi2_backbone2/func_grad.M,chi2_sugar/func_grad.M,chi2_noe/func_grad.M,chi2_unoe/func_grad.M])\n",
    "            if valtype == 1:\n",
    "                chi2_sys_list[s][0]+=np.sum([chi2_backbone1,chi2_backbone2,chi2_sugar,chi2_noe,chi2_unoe])/func_grad.M\n",
    "                chi2_sys_list[s][1]+=chi2_backbone1/func_grad.M\n",
    "                chi2_sys_list[s][2]+=chi2_backbone2/func_grad.M\n",
    "                chi2_sys_list[s][3]+=chi2_sugar/func_grad.M\n",
    "                chi2_sys_list[s][4]+=chi2_noe/func_grad.M\n",
    "                chi2_sys_list[s][5]+=chi2_unoe/func_grad.M\n",
    "            \n",
    "    chi2/=func_grad.M \n",
    "    chi2/=len(Sequences) \n",
    "\n",
    "    return chi2,chi2_sys_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d3093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kish(weight_list):\n",
    "    ave_kish=0\n",
    "    \n",
    "    for w in weight_list:\n",
    "        ave_kish+=np.sum(w)**2/np.sum(w**2)\n",
    "    \n",
    "    return ave_kish/len(weight_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda3e323",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the remaining data 70% training 30% validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77521f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimization_step(hyperparameter,alpha,prev_karplus_param):\n",
    "    print(hyperparameter,alpha)\n",
    "    \n",
    "    func_grad.alpha=alpha\n",
    "    func_grad.hyperparameter=hyperparameter\n",
    "        \n",
    "    #training\n",
    "    func_grad.selection_obs=func_grad.training_selection_obs\n",
    "    func_grad.selection_frames=func_grad.training_selection_frames\n",
    "    func_grad.selection_obs_gamma=func_grad.training_selection_obs_gamma\n",
    "    func_grad.selection_obs_beta=func_grad.training_selection_obs_beta\n",
    "    func_grad.selection_obs_sugar=func_grad.training_selection_obs_sugar\n",
    "    func_grad.selection_obs_noe=func_grad.training_selection_obs_noe\n",
    "    func_grad.selection_obs_unoe=func_grad.training_selection_obs_unoe\n",
    "   \n",
    "    \n",
    "    M_training=0\n",
    "    for s,Sequence in enumerate(Sequences):\n",
    "        M_training+=len(func_grad.selection_obs_gamma[s])\n",
    "        M_training+=len(func_grad.selection_obs_beta[s])\n",
    "        M_training+=len(func_grad.selection_obs_sugar[s])\n",
    "        M_training+=len(func_grad.selection_obs_noe[s])\n",
    "        M_training+=len(func_grad.selection_obs_unoe[s])\n",
    "\n",
    "    func_grad.M=M_training\n",
    "    \n",
    "    func_grad.counter=0\n",
    "    func_grad.lambdas=[[],[],[],[],[],[]]\n",
    "    \n",
    "    m=minimize(func_grad,x0=prev_karplus_param,method='L-BFGS-B', jac=True)\n",
    "    training_parameters_iter_scan=m.x\n",
    "    \n",
    "    func_grad.counter=0\n",
    "    new_chi_half,new_weights,new_lambdas=func_grad(m.x,opt=False,regularize=False)\n",
    "    \n",
    "    training_new_weights,validation_new_weights1,validation_new_weights2=compute_weights(m.x,new_lambdas,func_grad.training_selection_frames,func_grad.validation_selection_frames,cuda)\n",
    "    chi2,chi2_system=compute_chi(m.x,training_new_weights)\n",
    "    \n",
    "    training_chi2_iter_scan=chi2\n",
    "    training_chi2_sys_iter_scan=chi2_system\n",
    "    kish_size_training=compute_kish(training_new_weights)\n",
    "    training_kish_iter_scan=kish_size_training\n",
    "            \n",
    "\n",
    "    #compute validation quantities \n",
    "    func_grad.selection_frames=func_grad.validation_selection_frames\n",
    "    func_grad.selection_obs1=func_grad.validation_selection_obs1\n",
    "    func_grad.selection_obs_gamma1=func_grad.validation_selection_obs_gamma1\n",
    "    func_grad.selection_obs_beta1=func_grad.validation_selection_obs_beta1\n",
    "    func_grad.selection_obs_sugar1=func_grad.validation_selection_obs_sugar1\n",
    "    func_grad.selection_obs_noe1=func_grad.validation_selection_obs_noe1\n",
    "    func_grad.selection_obs_unoe1=func_grad.validation_selection_obs_unoe1\n",
    "    func_grad.selection_obs2=func_grad.validation_selection_obs2\n",
    "    func_grad.selection_obs_gamma2=func_grad.validation_selection_obs_gamma2\n",
    "    func_grad.selection_obs_beta2=func_grad.validation_selection_obs_beta2\n",
    "    func_grad.selection_obs_sugar2=func_grad.validation_selection_obs_sugar2\n",
    "    func_grad.selection_obs_noe2=func_grad.validation_selection_obs_noe2\n",
    "    func_grad.selection_obs_unoe2=func_grad.validation_selection_obs_unoe2\n",
    "    \n",
    "    M_validation=0\n",
    "    for s,Sequence in enumerate(Sequences):\n",
    "        M_validation+=len(func_grad.selection_obs_gamma1[s])+len(func_grad.selection_obs_gamma2[s])\n",
    "        M_validation+=len(func_grad.selection_obs_beta1[s])+len(func_grad.selection_obs_beta2[s])\n",
    "        M_validation+=len(func_grad.selection_obs_sugar1[s])+len(func_grad.selection_obs_sugar2[s])\n",
    "        M_validation+=len(func_grad.selection_obs_noe1[s])+len(func_grad.selection_obs_noe2[s])\n",
    "        M_validation+=len(func_grad.selection_obs_unoe1[s])+len(func_grad.selection_obs_unoe2[s])\n",
    "\n",
    "    func_grad.M=M_validation\n",
    "    chi2,chi2_system=compute_chi_val(m.x,validation_new_weights1,validation_new_weights2)\n",
    "    validation_chi2_iter_scan=chi2\n",
    "    validation_chi2_sys_iter_scan=chi2_system\n",
    "    kish_size_validation=compute_kish(validation_new_weights1)\n",
    "    kish_size_validation+=compute_kish(validation_new_weights2)\n",
    "    validation_kish_iter_scan=kish_size_validation\n",
    "            \n",
    "    \n",
    "    return (training_parameters_iter_scan,\n",
    "            training_chi2_iter_scan,\n",
    "            training_chi2_sys_iter_scan,\n",
    "            training_kish_iter_scan,\n",
    "            validation_chi2_iter_scan,\n",
    "            validation_chi2_sys_iter_scan,\n",
    "            validation_kish_iter_scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb0e059",
   "metadata": {},
   "outputs": [],
   "source": [
    "#before executing this script, create a dir 'datasave'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8789f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save all matrizes at every iteration\n",
    "\n",
    "def save(parameters,chi2_training,chi2_sys_training,kishsize_training,chi2_validation,chi2_sys_validation,kishsize_validation,cpt_matrix,scantype):\n",
    "    np.save(curr_dir+'/datasave/CV_207030_parameters_%s_300K_sigma03_9params.npy' %(iteration),parameters)\n",
    "    np.save(curr_dir+'/datasave/CV_207030_chi2_training_%s_300K_sigma03_9params.npy' %(iteration),chi2_training)\n",
    "    np.save(curr_dir+'/datasave/CV_207030_chi2_sys_training_%s_300K_sigma03_9params.npy' %(iteration),chi2_sys_training)\n",
    "    np.save(curr_dir+'/datasave/CV_207030_kishsize_training_%s_300K_sigma03_9params.npy' %(iteration),kishsize_training)\n",
    "    np.save(curr_dir+'/datasave/CV_207030_chi2_validation_%s_300K_sigma03_9params.npy' %(iteration),chi2_validation)\n",
    "    np.save(curr_dir+'/datasave/CV_207030_chi2_sys_validation_%s_300K_sigma03_9params.npy' %(iteration),chi2_sys_validation)\n",
    "    np.save(curr_dir+'/datasave/CV_207030_kishsize_validation_%s_300K_sigma03_9params.npy' %(iteration),kishsize_validation)\n",
    "    np.save(curr_dir+'/datasave/CV_207030_cpt_matrix_%s_300K_sigma03_9params.npy' %(iteration),cpt_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f196f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select which iteration run is performed (between 0 and 4)\n",
    "iteration=0\n",
    "\n",
    "scantypes=['betapass'] \n",
    "\n",
    "cuda=True #enable/disable GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55de16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all frame and observable selections\n",
    "#define the selection (either training or validation)\n",
    "\n",
    "func_grad.training_selection_frames=np.load(curr_dir+'/dataload/CV7030_training_selection_frames_%s_300K.npy' %iteration,allow_pickle=True)\n",
    "func_grad.validation_selection_frames=np.load(curr_dir+'/dataload/CV7030_validation_selection_frames_%s_300K.npy' %iteration,allow_pickle=True)\n",
    "func_grad.training_selection_frames=np.array(func_grad.training_selection_frames,dtype=np.int)\n",
    "func_grad.validation_selection_frames=np.array(func_grad.validation_selection_frames,dtype=np.int)\n",
    "    \n",
    "def load_selector_sys(label,label2=1):\n",
    "    if label=='training':\n",
    "        out=np.load(curr_dir+'/dataload/CV7030_%s_selection_obs_%s_%s_300K.npy' %(label,Sequence,iteration),allow_pickle=True)\n",
    "    else:\n",
    "        out=np.load(curr_dir+'/dataload/CV7030_%s_selection%s_obs_%s_%s_300K.npy' %(label,label2,Sequence,iteration),allow_pickle=True)\n",
    "    return np.array(out,dtype=np.int) \n",
    "\n",
    "func_grad.training_selection_obs=[]\n",
    "func_grad.validation_selection_obs1=[]\n",
    "func_grad.validation_selection_obs2=[]\n",
    "for s,Sequence in enumerate(Sequences):\n",
    "    func_grad.training_selection_obs.append(load_selector_sys('training'))\n",
    "    func_grad.validation_selection_obs1.append(load_selector_sys('validation','1'))\n",
    "    func_grad.validation_selection_obs2.append(load_selector_sys('validation','2'))\n",
    "    \n",
    "\n",
    "def load_selector(label1,label2,label3=1):\n",
    "    if label1=='training':\n",
    "        out=np.load(curr_dir+'/dataload/CV7030_%s_selection_%s_%s_%s_300K.npy' %(label1,label2,Sequence,iteration),allow_pickle=True)\n",
    "    else:\n",
    "        out=np.load(curr_dir+'/dataload/CV7030_%s_selection%s_%s_%s_%s_300K.npy' %(label1,label2,label3,Sequence,iteration),allow_pickle=True)\n",
    "    return np.array(out,dtype=np.int) \n",
    "\n",
    "func_grad.training_selection_obs_gamma=[]\n",
    "func_grad.validation_selection_obs_gamma1=[]\n",
    "func_grad.validation_selection_obs_gamma2=[]\n",
    "func_grad.training_selection_obs_beta=[]\n",
    "func_grad.validation_selection_obs_beta1=[]\n",
    "func_grad.validation_selection_obs_beta2=[]\n",
    "func_grad.training_selection_obs_sugar=[]\n",
    "func_grad.validation_selection_obs_sugar1=[]\n",
    "func_grad.validation_selection_obs_sugar2=[]\n",
    "func_grad.training_selection_obs_noe=[]\n",
    "func_grad.validation_selection_obs_noe1=[]\n",
    "func_grad.validation_selection_obs_noe2=[]\n",
    "func_grad.training_selection_obs_unoe=[]\n",
    "func_grad.validation_selection_obs_unoe1=[]\n",
    "func_grad.validation_selection_obs_unoe2=[]\n",
    "for s,Sequence in enumerate(Sequences):\n",
    "    \n",
    "    func_grad.training_selection_obs_gamma.append(load_selector('training','gamma'))\n",
    "    func_grad.validation_selection_obs_gamma1.append(load_selector('validation','1','gamma'))\n",
    "    func_grad.validation_selection_obs_gamma2.append(load_selector('validation','2','gamma'))\n",
    "    func_grad.training_selection_obs_beta.append(load_selector('training','beta'))\n",
    "    func_grad.validation_selection_obs_beta1.append(load_selector('validation','1','beta'))\n",
    "    func_grad.validation_selection_obs_beta2.append(load_selector('validation','2','beta'))\n",
    "    func_grad.training_selection_obs_sugar.append(load_selector('training','sugar'))\n",
    "    func_grad.validation_selection_obs_sugar1.append(load_selector('validation','1','sugar'))\n",
    "    func_grad.validation_selection_obs_sugar2.append(load_selector('validation','2','sugar'))\n",
    "    func_grad.training_selection_obs_noe.append(load_selector('training','noe'))\n",
    "    func_grad.validation_selection_obs_noe1.append(load_selector('validation','1','noe'))\n",
    "    func_grad.validation_selection_obs_noe2.append(load_selector('validation','2','noe'))\n",
    "    func_grad.training_selection_obs_unoe.append(load_selector('training','unoe'))\n",
    "    func_grad.validation_selection_obs_unoe1.append(load_selector('validation','1','unoe'))\n",
    "    func_grad.validation_selection_obs_unoe2.append(load_selector('validation','2','unoe'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c226821",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps=1e-30\n",
    "regularization='L2'\n",
    "\n",
    "resolution=30\n",
    "\n",
    "hyperparameter_list= np.geomspace(1e-3, 1e6, num=resolution-1)\n",
    "hyperparameter_list = np.insert(hyperparameter_list, 0, 0.0, axis=0)\n",
    "alpha_list= np.geomspace(1e1, 1e10, num=resolution)\n",
    "\n",
    "\n",
    "i=hyperparameter_list.shape[0]-1\n",
    "j=alpha_list.shape[0]-1\n",
    "\n",
    "try:\n",
    "    matrix=np.load(curr_dir+'/datasave/CV_207030_cpt_matrix_%s_300K_sigma03_9params.npy' %(iteration))\n",
    "    sc_cpt=np.load(curr_dir+'/datasave/CV_207030_cpt_scantype_%s_300K_sigma03_9params.npy' %(iteration),allow_pickle=True)[0]\n",
    "    training_parameters_iter_scan_mat=np.load(curr_dir+'/datasave/CV_207030_parameters_%s_300K_sigma03_9params.npy' %(iteration),allow_pickle=True)\n",
    "    training_chi2_iter_scan_mat=np.load(curr_dir+'/datasave/CV_207030_chi2_training_%s_300K_sigma03_9params.npy' %(iteration))\n",
    "    training_chi2_sys_iter_scan_mat=np.load(curr_dir+'/datasave/CV_207030_chi2_sys_training_%s_300K_sigma03_9params.npy' %(iteration),allow_pickle=True)\n",
    "    training_kish_iter_scan_mat=np.load(curr_dir+'/datasave/CV_207030_kishsize_training_%s_300K_sigma03_9params.npy' %(iteration))\n",
    "    validation_chi2_iter_scan_mat=np.load(curr_dir+'/datasave/CV_207030_chi2_validation_%s_300K_sigma03_9params.npy' %(iteration))\n",
    "    validation_chi2_sys_iter_scan_mat=np.load(curr_dir+'/datasave/CV_207030_chi2_sys_validation_%s_300K_sigma03_9params.npy' %(iteration),allow_pickle=True)\n",
    "    validation_kish_iter_scan_mat=np.load(curr_dir+'/datasave/CV_207030_kishsize_validation_%s_300K_sigma03_9params.npy' %(iteration))\n",
    "except FileNotFoundError:\n",
    "    matrix=np.zeros((i+1,j+1))\n",
    "    sc_cpt='initialize'\n",
    "    training_parameters_iter_scan_mat=np.zeros((i+1,j+1),dtype='object')\n",
    "    training_chi2_iter_scan_mat=np.zeros((i+1,j+1))+1e6\n",
    "    training_chi2_sys_iter_scan_mat=np.zeros((i+1,j+1),dtype='object')\n",
    "    training_kish_iter_scan_mat=np.zeros((i+1,j+1))\n",
    "    validation_chi2_iter_scan_mat=np.zeros((i+1,j+1))\n",
    "    validation_chi2_sys_iter_scan_mat=np.zeros((i+1,j+1),dtype='object')\n",
    "    validation_kish_iter_scan_mat=np.zeros((i+1,j+1))\n",
    "\n",
    "\n",
    "    \n",
    "pi=i\n",
    "pj=j\n",
    "while 0 in matrix:\n",
    "    while pi >=0:\n",
    "        if matrix[pi,pj]!=0:\n",
    "            pi-=1\n",
    "        else:\n",
    "            \n",
    "            for scantype in enumerate(scantypes):\n",
    "                print(scantype)\n",
    "                prev_karplus_param=np.random.uniform(-1,1,size=(9,))\n",
    "                if scantype == 'skip': \n",
    "                    continue\n",
    "                else:\n",
    "                    if pi == hyperparameter_list.shape[0]-1 or pj==alpha_list.shape[0]-1:\n",
    "                        prev_karplus_param=np.random.uniform(-1,1,size=(9,)) \n",
    "                    else:\n",
    "                        if scantype=='betapass':\n",
    "                            prev_karplus_param=training_parameters_iter_scan_mat[pi+1,pj] \n",
    "                    output=optimization_step(hyperparameter_list[pi],alpha_list[pj],prev_karplus_param)\n",
    "                    \n",
    "                    if output[1] < training_chi2_iter_scan_mat[pi,pj]:\n",
    "                        training_parameters_iter_scan_mat[pi,pj]=output[0]\n",
    "                        training_chi2_iter_scan_mat[pi,pj]=output[1]\n",
    "                        training_chi2_sys_iter_scan_mat[pi,pj]=output[2]\n",
    "                        training_kish_iter_scan_mat[pi,pj]=output[3]\n",
    "                        validation_chi2_iter_scan_mat[pi,pj]=output[4]\n",
    "                        validation_chi2_sys_iter_scan_mat[pi,pj]=output[5]\n",
    "                        validation_kish_iter_scan_mat[pi,pj]=output[6]\n",
    "                        matrix[pi,pj]=1\n",
    "                        save(training_parameters_iter_scan_mat,\n",
    "                                training_chi2_iter_scan_mat,\n",
    "                                training_chi2_sys_iter_scan_mat,\n",
    "                                training_kish_iter_scan_mat,\n",
    "                                validation_chi2_iter_scan_mat,\n",
    "                                validation_chi2_sys_iter_scan_mat,\n",
    "                                validation_kish_iter_scan_mat,\n",
    "                                matrix,scantype)\n",
    "                    np.save(curr_dir+'/datasave/CV_207030_cpt_scantype_%s_300K_sigma03_9params.npy' %(iteration),np.array([scantype],dtype='object'))\n",
    "                    sc_cpt=scantype\n",
    "    pi,pj=i,j\n",
    "    while pj >=0:\n",
    "        if matrix[pi,pj]!=0:\n",
    "            pj-=1\n",
    "        else:\n",
    "            for scantype in enumerate(scantypes):\n",
    "                print(scantype)\n",
    "                prev_karplus_param=np.random.uniform(-1,1,size=(9,))\n",
    "                if scantype == 'skip':\n",
    "                    continue\n",
    "                else:\n",
    "                    if pi == hyperparameter_list.shape[0]-1 or pj==alpha_list.shape[0]-1:\n",
    "                        prev_karplus_param=np.random.uniform(-1,1,size=(9,)) \n",
    "                    else:\n",
    "                        if scantype=='betapass':\n",
    "                            prev_karplus_param=training_parameters_iter_scan_mat[pi+1,pj] \n",
    "                    output=optimization_step(hyperparameter_list[pi],alpha_list[pj],prev_karplus_param)\n",
    "                    \n",
    "                    if output[1] < training_chi2_iter_scan_mat[pi,pj]:\n",
    "                        training_parameters_iter_scan_mat[pi,pj]=output[0]\n",
    "                        training_chi2_iter_scan_mat[pi,pj]=output[1]\n",
    "                        training_chi2_sys_iter_scan_mat[pi,pj]=output[2]\n",
    "                        training_kish_iter_scan_mat[pi,pj]=output[3]\n",
    "                        validation_chi2_iter_scan_mat[pi,pj]=output[4]\n",
    "                        validation_chi2_sys_iter_scan_mat[pi,pj]=output[5]\n",
    "                        validation_kish_iter_scan_mat[pi,pj]=output[6]\n",
    "                        matrix[pi,pj]=1\n",
    "                        save(training_parameters_iter_scan_mat,\n",
    "                                training_chi2_iter_scan_mat,\n",
    "                                training_chi2_sys_iter_scan_mat,\n",
    "                                training_kish_iter_scan_mat,\n",
    "                                validation_chi2_iter_scan_mat,\n",
    "                                validation_chi2_sys_iter_scan_mat,\n",
    "                                validation_kish_iter_scan_mat,\n",
    "                                matrix,scantype)\n",
    "                    np.save(curr_dir+'/datasave/CV_207030_cpt_scantype_%s_300K_sigma03_9params.npy' %(iteration),np.array([scantype],dtype='object'))\n",
    "                    sc_cpt=scantype\n",
    "    i,j=i-1,j-1\n",
    "    pi,pj=i,j\n",
    "\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "714552b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8ce98a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all available iteration on the CV landscape and compute averages\n",
    "#set the following path to the directory containing your 'datasave' dir\n",
    "load_dir='your_dir'\n",
    "\n",
    "cv_iterations=[0,1,2,3,4] \n",
    "for i,iteration in enumerate(cv_iterations):\n",
    "    training_chi2_iter_scan_mat=np.load('CV_files/CV_207030_chi2_training_%s_300K_sigma03_9params.npy' %(iteration))\n",
    "    training_kish_iter_scan_mat=np.load('CV_files/CV_207030_kishsize_training_%s_300K_sigma03_9params.npy' %(iteration))\n",
    "    validation_chi2_iter_scan_mat=np.load('CV_files/CV_207030_chi2_validation_%s_300K_sigma03_9params.npy' %(iteration))\n",
    "    validation_kish_iter_scan_mat=np.load('CV_files/CV_207030_kishsize_validation_%s_300K_sigma03_9params.npy' %(iteration))\n",
    "    #training_chi2_iter_scan_mat=np.load(load_dir+'datasave/CV_207030_chi2_training_%s_300K_sigma03_9params.npy' %(iteration))\n",
    "    #training_kish_iter_scan_mat=np.load(load_dir+'datasave/CV_207030_kishsize_training_%s_300K_sigma03_9params.npy' %(iteration))\n",
    "    #validation_chi2_iter_scan_mat=np.load(load_dir+'datasave/CV_207030_chi2_validation_%s_300K_sigma03_9params.npy' %(iteration))\n",
    "    #validation_kish_iter_scan_mat=np.load(load_dir+'datasave/CV_207030_kishsize_validation_%s_300K_sigma03_9params.npy' %(iteration))\n",
    "\n",
    "\n",
    "    training_chi2_iter_scan_mat[training_chi2_iter_scan_mat ==1e6] = 0\n",
    "    if i==0:\n",
    "        chi2_training=training_chi2_iter_scan_mat\n",
    "        chi2_validation=validation_chi2_iter_scan_mat \n",
    "        kishsize_training=training_kish_iter_scan_mat\n",
    "        kishsize_validation=validation_kish_iter_scan_mat\n",
    "    else:\n",
    "        chi2_training+=training_chi2_iter_scan_mat\n",
    "        chi2_validation+=validation_chi2_iter_scan_mat \n",
    "        kishsize_training+=training_kish_iter_scan_mat\n",
    "        kishsize_validation+=validation_kish_iter_scan_mat\n",
    "\n",
    "chi2_training/=len(cv_iterations)\n",
    "chi2_validation/=len(cv_iterations)\n",
    "kishsize_training/=len(cv_iterations)\n",
    "kishsize_validation/=len(cv_iterations)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "185dd769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASQAAAD5CAYAAACOLkipAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAATbElEQVR4nO3da6xlZX3H8e/vnDkzwwwgY6g4BRQktGlDUjQnaEtjsN7QmqJJNZLYoLGOL6TVpk2rvIE3TUjjjReNyahUjJdqvFTSEC8hGto3lAEJIKPV0imMTBkQFBBh5uz964u9jz23tfaes9be6zmzfx+yMufsdfuz5pz/PLf1PLJNREQJ5roOICJiWRJSRBQjCSkiipGEFBHFSEKKiGIkIUVEMbY1OVnS5cANwDzwKdvX1x2/sH23d+7cU7l/7tlj1Scv9TYXJIA0uXPnavbP1ed7z89X7utvr79vb0f1/v6O+qEc23csVe47feHZ2nN3zz1XuW+Hqq8LMF/zLOeo//9t8DdYJE3o/+jQQ8d57PFeo4u//lW7/bPHx/t9u/Oe575l+/Im91tp0wlJ0jzwj8BrgcPAHZJutn1/1Tk7d+5h8eVXV15z5/0/rdzXf+Lnmw11ZGKgJjFoW/0j0o7tlft86q7ac/t7Tq3c98zZp9Se+4vzq+N68rfqE8OLLzhaue81L/xh7bmX7Pqvyn0XLDxRe+7zapL3Li3Unrug6r+jUcmsRPOaTOXkktc/1PgaP3u8x39860VjHTu/98dnNr7hCk2eyiXAT2w/YPsY8M/AFe2EFRFdMdAf87+2NamynQ2sTMeHgZc3CyciumbMcTdoImmgSULaqJy8rvFC0j5gH8COnWc0uF1ETMskSj/jaJKQDgPnrvj+HODhtQfZ3g/sBzjt9HPy4lxE4YzpdfSOa5M2pDuACyWdL2k78Hbg5nbCiogu9fFYW9s2XUKyvSTpauBbDLr9b7T9g9Yii4hOGOhNINmMo9E4JNu3ALe0FEtEFGISpZ9xNEpIEXHyMXC8ozakJKSIWMV4a1bZIuIkZOh11B+ehBQRqwxGancjCSki1hC9jt4PTEKKiFUGjdpJSBFRgME4pCSkiChEPyWkiChBSkgRUQwjeh3Nbp2EFBHrpMoWEUUw4pirpwyepCSkiFhlMDAyVbaIKEQatSOiCLboOSWkiChEPyWkiCjBoFG7m9SQhBQRq6RROyKK0ss4pIgoQUZqR0RR+rPQy9ZfEL/cu1C5f+f9UwwmIjY0eLl2BhJSRJTPiON5dSQiSmCTgZERUQplYGRElMGkhBQRBUmjdkQUwSgTtEVEGQbLIG3Bd9kkHQKeAnrAku3FuuPnjpvdR443uWVETFy7C0VK+ivgzxnkunuBd9l+dqNj26govsr2xaOSUURsDWYwUnucbRRJZwN/CSzavgiYB95edXyqbBGxTsszRm4DTpF0HNgFPFx1YNMSkoFvS7pT0r6G14qIAthqrYRk+6fAh4EHgSPAL2x/u+r4pgnpUtsvA94AvE/SK9ceIGmfpAOSDhw//suGt4uISRs0as+PtQFnLv9+D7dVBRNJe4ArgPOB3wR2S3pH1b0bVdlsPzz886ikrwOXALetOWY/sB/gtNPPcZP7RcQ0nNCc2o+NaD9+DfDfth8FkPQ14A+Az2108KZLSJJ2Szpt+WvgdcB9m71eRJRh0KitsbYxPAi8QtIuSQJeDRysOrhJCeks4OuDe7AN+ILtbza4XsTM6Llfu39e3YyUXtbWSG3bt0v6CnAXsAR8n2GNaSObTki2HwB+b7PnR0SZ2h6pbfta4Npxjk23f0Ssk0n+I6IINhzvJyFFRAEGVbYkpIgoRMsjtceWhBQRqyx3+3chCSki1kiVLSJWqBunNI0xSplTOyKKMOhlyzJIEVGATGEbEUVJlS0iipBetogoSnrZIqIItlhKQupQv34qiIiS1A0JMO3MgZgqW0QUIW1IEVGUJKSIKELGIUVEUTIOKSKKYMNSJmiLiFKkyhYRRZitNqS6YRKn7Kze90TrkUREBc9MQoqI4qVROyKKYKcNKSKKIXrpZYuIUqQNKSKKkHfZIqIcHrQjdWFkQpJ0I/Am4Kjti4afPR/4EnAecAh4m+3mHfPP/KrxJaI7XS0u2B8x5cZcR3FtZV31so3TcvUZ4PI1n30QuNX2hcCtw+8j4iTgYaP2OFvbRl7R9m3A42s+vgK4afj1TcCb2w0rIrpkj7e1bbNtSGfZPgJg+4ikF7QYU0R07KTtZZO0D9gHsGPnGZO+XUQ0NCj9lNuGtJFHJO0FGP55tOpA2/ttL9peXFjYvcnbRcQ09a2xtrZtNiHdDFw1/Poq4BvthBMRJSi2DUnSF4HLgDMlHQauBa4Hvizp3cCDwFvbDy0iumBEv9RXR2xfWbHr1Sd6MwHaZFp1g3SsUcsczc/X3HjzSySp39Hosga37XW0Htcofar/HuY2XdCPKh395OZvMiLWGDZqj7ONQ9IZkr4i6YeSDkr6/apj8+pIRKzXbhHpBuCbtv9U0nZgV9WBSUgRsU5b3f6STgdeCbxzcF0fA45VHZ8qW0SsYqDf11gbg86uAyu2fWsu9xLgUeCfJH1f0qckVY7/SUKKiNUMWONt8NjyOMPhtn/N1bYBLwM+YfulwC+pefc1CSki1mlxHNJh4LDt24fff4VBgtrQdNuQ7Nqu8CZd+12pi3mig+8bPKomI2z7E/o3rK5bH2CemqEZI69d/bAyNUmFln4Vbf+vpIck/bbtHzEYLnR/1fFp1I6INcbv0h/TXwCfH/awPQC8q+rAJKSIWK/Fyortu4HFcY5NQoqI1Qzun6TTj0TEVpSEFBGlKHWS/4iYQUlIEVGE5YGRHZh6QtJSTeqd0HQdo8Y3bXZKlMbq7ttRSE2Wv+mN+CEetVzRZo0aw1Q3PcmkYpqkaYydKnZdtoiYQelli4hSKCWkiCiCSaN2RJRCs9OoHRFbQEpIEVGMza9t0ch0E1If5o71avbX7WuQsucaFD9H3bdu/yT7TmsurVHd7w2K470JdTn3RvyTPFfzLOc1arjB5n+7ulrRpNNpUWZpHFJElC+9bBFRjo4SUqawjYhipIQUEeukyhYRZTB5dSQiCpISUkSUotgqm6QbgTcBR21fNPzsOuA9DFakBLjG9i0jr2WjY0vVB/RqxiG5wUit/oi2e1Vfe+TUJXU7R41DqltCqcnAtAY/TD1vvp9j1NQlvZq/w1HTgPTrHsiImEeNU6q9b0djmOqex4Kql4RSW+OXCu5l+wxw+Qaff8z2xcNtZDKKiC3EY24tG1lCsn2bpPPav3VElEjursrWZBzS1ZLukXSjpD2tRRQR3etrvK1lm01InwAuAC4GjgAfqTpQ0j5JByQdOLb0zCZvFxHTtFxKGrW1bVMJyfYjtnu2+8AngUtqjt1ve9H24vZtuzYbZ0RMU0dtSJtKSJL2rvj2LcB97YQTEZ0bs3Q0iRLSON3+XwQuA86UdBi4FrhM0sWD0DkEvHesu9noeHXXvo9XDwlwg+lHNFffdeuaqRZG1pIbDUeou279qU1+GJr8HDUZFlAzqGOiehOaBqau+x3qhwyMGhJQd27d6i5uq9hS6jgk21du8PGnJxBLRBSi0Ti4BvK2f0QUI6+ORMR6pVbZImLGdDgwMgkpItZLQoqIYiQhRUQJRHe9bFNNSJ6fY+l5p1Tun5/Q9CMeMf3IiOEkM6XEJZIG1677J7v+Z2NSSxk1mZpk1Ll1Mc+rel8r049s0ZdrI+Jk1eKrI5LmJX1f0r+OOjYJKSLWa/ddtvcDB8c5MAkpItZp6102SecAfwx8apz7JiFFxHrtlZA+Dvwtoxr6hpKQImI1D3rZxtkYvHR/YMW2b/kykpbn4r9z3Fun2z8i1hu/fegx24sV+y4F/kTSG4GdwOmSPmf7HVUXm35CqumVrF3ho8kUEk16QvsdDchooqMu21nTZFqTUSuhzE1wCMU42uj2t/0h4EMAki4D/qYuGUFKSBGxkYzUjogiTGB6WtvfA7436rgkpIhYReRt/4goSBJSRJQjCSkiipGEFBFFmJUZI3W8x8KRn1fu72qZnIjSLNX8NvRrxj+d9MsgRcTsmYkJ2iJia5iJKltEbAETGBg5riSkiFgvCSkiSpCR2hFRFPW7yUgjE5Kkc4HPAi9kMOvbfts3SHo+8CXgPOAQ8DbbT9RezIbjSw1DjijDqClE6oyauqTu2nUrlrSSRjpsQxpnxsgl4K9t/w7wCuB9kn4X+CBwq+0LgVuH30fESaCtObVP1MiEZPuI7buGXz/FYPWAs4ErgJuGh90EvLn98CKiE+2uOjK2E2pDknQe8FLgduAs20dgkLQkvaD98CKiC8U3aks6Ffgq8AHbT2rM+vNw0u99ADvnT9tMjBExbQW3ISFpgUEy+rztrw0/fkTS3uH+vcDRjc61vd/2ou3F7XPVy2hHRCFObNWRVo1MSBoUhT4NHLT90RW7bgauGn59FfCN9sOLiGlbHofURaP2OFW2S4E/A+6VdPfws2uA64EvS3o38CDw1vbDi4hONFnlp4GRCcn2v1O9kNCrT+huvR79J35euVvz89VxnNCNIqKJ4hu1I2JG5OXaiChJ5kOKiGIkIUVEGUy5jdoRMXvSqB0R5ZiJhDQ/z9yeMyp3+8mnphfLNHRU7I1oIhO0RUQ57HInaIuIGZQSUkSUIlW2iCiDgVTZIqIYKSFFRClSZYuIYsxGL5uAuqlvty9MLZQoS29EHWGucgac7oxayqhOkyWUJi5v+0dEKQYDI7vJSGPNqR0RM6Y/5jaCpHMlfVfSQUk/kPT+uuNTQoqIdVosIS0vNHuXpNOAOyV9x/b9Gx2cElJErDbuIpFj5KyahWY3lBJSRKwxmXfZ1iw0u6EkpIhYb/wq25mSDqz4fr/t/WsPWrvQbNXFptztL1iovqW8c4rBxGb0J1TLny+wWx+adc83GRbQKZ/QFLaP2V6sO6BiodkNpYQUEeu1lExrFprdUBq1I2K9lhq1+f+FZv9I0t3D7Y1VB6eEFBHrqN/OsiMjFppdJwkpIlYzYw16nIQkpIhYRbizV0eSkCJivSSkiChGqQlJ0rnAZ4EXMqhZ7rd9g6TrgPcAjw4Pvcb2LbUXm5ujf9op1bsfXxov6jjplDr9SN1YoqKnEGmi8DakDV+OG+77mO0PTy68iOhCW71sJ2pkQrJ9BDgy/PopSbUvx0XEVufOqmwnNDByg5fjrpZ0j6QbJe1pO7iI6IAZJKRxtpaNnZA2eDnuE8AFwMUMSlAfqThvn6QDkg4cW3qmecQRMXktTdB2osZKSBu9HGf7Eds9233gk8AlG51re7/tRduL27ftaivuiJgg2WNtbRuZkKpejpO0d8VhbwHuaz26iOhGR1W2cXrZll+Ou1fS3cPPrgGulHQxgxrnIeC9TYPpnfm8yn1zjz5We27/ueea3j7ihIyaXqRuWECTcyfOhl65vWxVL8fVjzmKiK2r1IGRETGDkpAioggGZmLl2ojYAgwutA0pImaMKbdROyJmUNqQIqIYs5CQLPDCfPX+bdXjNLWwUH/xZ5+t3neSzhJxMil1GaRJKXvqku5erk0JKSJWM1Dq9CMRMYNSQoqIMhT86khEzBiDMw4pIoqRkdoRUYxZaEPq75jn6Rfvrtx/6gNPV+7zr35Vf/G56uEEUb5SVx2p06TrvvjpR9LLFhHFmIUSUkRsBca9Xid3TkKKiNUy/UhEFCXd/hFRAgNOCSkiiuBM0BYRBemqUVueYveepEeB/1nx0ZlA/fpG01diTFBmXCXGBGXGNa2YXmz7N5pcQNI3GcQ7jsdsX97kfqvuPc2EtO7m0gHbi50FsIESY4Iy4yoxJigzrhJjKtFYS2lHRExDElJEFKPrhLS/4/tvpMSYoMy4SowJyoyrxJiK02kbUkTESl2XkCIifq2ThCTpckk/kvQTSR/sIoaNSDok6V5Jd0s60FEMN0o6Kum+FZ89X9J3JP14+OeeQuK6TtJPh8/rbklvnHJM50r6rqSDkn4g6f3Dzzt9XjVxdfq8toKpV9kkzQP/CbwWOAzcAVxp+/6pBrIBSYeARdudjWGR9ErgaeCzti8afvYPwOO2rx8m8D22/66AuK4Dnrb94WnGsiKmvcBe23dJOg24E3gz8E46fF41cb2NDp/XVtBFCekS4Ce2H7B9DPhn4IoO4iiS7duAx9d8fAVw0/Drmxj8cE9VRVydsn3E9l3Dr58CDgJn0/HzqokrRugiIZ0NPLTi+8OU85dl4NuS7pS0r+tgVjjL9hEY/LADL+g4npWulnTPsEo39arkMknnAS8Fbqeg57UmLijkeZWqi4S00dycpXT1XWr7ZcAbgPcNqylR7RPABcDFwBHgI10EIelU4KvAB2w/2UUMG9kgriKeV8m6SEiHgXNXfH8O8HAHcaxj++Hhn0eBrzOoXpbgkWG7xHL7xNGO4wHA9iO2ex6smfNJOnhekhYY/NJ/3vbXhh93/rw2iquE51W6LhLSHcCFks6XtB14O3BzB3GsImn3sAESSbuB1wH31Z81NTcDVw2/vgr4Roex/NryL/3QW5jy85Ik4NPAQdsfXbGr0+dVFVfXz2sr6GRg5LC78+PAPHCj7b+fehBrSHoJg1IRDKZl+UIXcUn6InAZg7etHwGuBf4F+DLwIuBB4K22p9rAXBHXZQyqHwYOAe9dbruZUkx/CPwbcC+wPIHPNQzaazp7XjVxXUmHz2sryEjtiChGRmpHRDGSkCKiGElIEVGMJKSIKEYSUkQUIwkpIoqRhBQRxUhCiohi/B+2H59EwqMEDgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUQAAAD8CAYAAAAPBN1qAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAez0lEQVR4nO3df6yc1Z3f8ffHv2JDYmLD4k1tdmEXK11AClksQ5tqRdaJ7WyrNZGgMtWW29aqI0S2SbVSF/KPU5AlqJJlg1pQneBiaILxsmGxViHkymyUVgJjQ2jAEOrbwOIbUzvmOsRpYuN777d/PN/BM3fmmXl87/j+ms8rejQz53nOmcMQvvec55znHEUEZmYGc6a6AmZm04UDoplZckA0M0sOiGZmyQHRzCw5IJqZJQdEMzunJP17SQckvSLpUUkLJS2V1C/pYL4uqbv+DkkDkl6XtK4u/RpJL+e5+yQp0z8g6bFM3yvp0ro8ffkdByX1daqrA6KZnTOSlgP/DlgVEVcBc4GNwO3AnohYCezJz0i6Is9fCawH7pc0N4t7ANgMrMxjfaZvAo5HxOXAvcA9WdZSYAtwLbAa2FIfeFtxQDSzc20esEjSPOA84DCwAdiR53cAN+T7DcDOiDgVEW8AA8BqSR8BFkfEs1E8TfLwmDy1sh4H1mTrcR3QHxFDEXEc6OdMEC2t6KRZoA/EQs4vPa8FC0rPjS5qX9XhhSrPu7D90zjzFoyUnls4d7ht3vlzyvMuUIe8Ks87v1NeRkvPzVX5bwEwl/LzanPOpr83D53m2NDIhP4lrvvk+fHOUPn/N+u98KNTB4CTdUnbImJb7UNE/FTSV4C3gF8D34uI70laFhFv5zVvS7o4sywHnqsrbzDTTuf7sem1PIeyrGFJ7wIX1qe3yNPShAKipPXA1yiawd+IiLvbXb+Q87l2zqfKK7P8ktJz/+/KZW3r8s7vzS8998uVp9vmXXbJ8dJzl3/4WNu8yxf9vPTcigXl5QL8g/nl539zXnm5AL8591el55bOad/w/+CcD5Sem/9+78RmotXrDnW+qIN3hkZ4/unfqnTt3I8cPBkRq8rOZxd1A3AZ8HPgryT9SZsiWwXzaJM+3jwtjbvLnP36/wJ8BrgCuDn7/2Y2gwUwWvF/FXwKeCMifhYRp4FvA/8YOJLdYPL1aF4/CNS3jFZQdLEH8/3Y9IY82S2/ABhqU1apidxDXA0MRMRPIuI9YCfFXwIzm8GC4HSMVDoqeAu4TtJ5eV9vDfAasBuojfr2AU/m+93Axhw5voxi8OT57F6fkHRdlnPLmDy1sm4Ensn7jE8DayUtyZbq2kwrNZEuc6v++bVjL5K0mWJkiIWcN4GvM7PJUrH111FE7JX0OPAiMAz8ENgGfBDYJWkTRdC8Ka8/IGkX8Gpef1vE+5H3VuAhYBHwVB4ADwKPSBqgaBluzLKGJN0F7Mvr7oyIoXb1nUhArNQ/zxus2wAWa6nXGjOb5oJgpIvLAkbEForpL/VOUbQWW12/FdjaIn0/cFWL9JNkQG1xbjuwvWpdJxIQz7p/bmYzw2j7sYdZayIBcR+wMvv5P6Vopv6LrtTKzKZMACMOiGcn5/t8nuIm5Vxge0Qc6FrNzGzKuIU4DhHxHeA7XaqLmU0DAZzu0a1FJvVJFTOb/oJwl9nMDICAkd6Mhw6IZtaoeFKlNzkgmtkYYqRHF/lwQDSzBsWgigOimVnOQ3RANDMDYNQtRDMztxDNzN4XiJEe3V3EAdHMmrjLbGZG0UJ8L3pzKwkHRDNrUEzMdpfZzAzwoIqZGQARYiTcQjQzA2C0R1uIvflnwMxKFYMq8yodnUj6qKSX6o5fSPqipKWS+iUdzNcldXnukDQg6XVJ6+rSr5H0cp67L3ffI3foeyzT90q6tC5PX37HQUl9dOCAaGYNaoMqVY6OZUW8HhFXR8TVwDXAr4AngNuBPRGxEtiTn8m93TcCVwLrgftzD3iAByh28FyZx/pM3wQcj4jLgXuBe7KspRSbW11LsW3ylvrA24oDopk1GQlVOs7SGuD/RMTfU+zhviPTdwA35PsNwM6IOBURbwADwOrczH5xRDybey4/PCZPrazHgTXZelwH9EfEUEQcB/o5E0Rb8j1EM2twlk+qXCRpf93nbbn1cCsbgUfz/bLcfJ6IeFvSxZm+HHiuLs9gpp3O92PTa3kOZVnDkt4FLqT13vHLacMB0cyajFYfZT4WEas6XSRpAfDHwB2dLm2RFm3Sx5unJXeZzaxBsbjDnErHWfgM8GJEHMnPR7IbTL4ezfSy/d4H8/3Y9IY8kuYBFwBDbcoq5YBoZg0CcTrmVjrOws2c6S4D7AZqo759wJN16Rtz5PgyisGT57N7fULSdXl/8JYxeWpl3Qg8k/cZnwbWSlqSgylrM62Uu8xm1iCCrk7MlnQe8Gngc3XJdwO7JG0C3gJuKr47DkjaBbwKDAO3RcRI5rkVeAhYBDyVB8CDwCOSBihahhuzrCFJdwH78ro7I2KoXV0dEM1sDHV1YnZE/IpikKM+7R2KUedW128FtrZI3w9c1SL9JBlQW5zbDmyvWlcHRDNrEHS3hTiTOCCaWRMvEGtmRjGo4gVizcyobUPam6FhQv/Ukt4ETgAjwHCVCZpmNt15o/qJ+GREHOtCOWY2DQRn9aTKrNKb7WIza6tXW4gT/TMQwPckvSBpczcqZGZTK0KMxpxKx2wz0RbiJyLicK5U0S/pxxHxg/oLMlBuBljIeRP8OjM714pBld7cdW9CIT4iDufrUYpFH1e3uGZbRKyKiFXz+cBEvs7MJkWxp0qVY7YZ9z+RpPMlfaj2nuLB6Ve6VTEzmxrFoIoqHbPNRLrMy4AncluDecC3IuK7XamVmU0pP6lyliLiJ8DHulgXM5sG/KSKmVmdKhtIzUYOiGbWIAJOjzogmplll9kB0cwM6N0nVRwQzaxBbdpNL3JANLMxerfL3Jv/1GbW1mjuq9LpqELShyU9LunHkl6T9I8kLZXUL+lgvi6pu/4OSQOSXpe0ri79Gkkv57n7cvc9coe+xzJ9r6RL6/L05XcclNRHBw6IZtagGGWeW+mo6GvAdyPiH1LMXX4NuB3YExErgT35GUlXUOyadyWwHrhfUu2LHqBYF2FlHuszfRNwPCIuB+4F7smylgJbgGspHiveUh94W3FANLMGtYnZ3Xh0T9Ji4A8otgolIt6LiJ8DG4AdedkO4IZ8vwHYGRGnIuINYABYnZvZL46IZ3PP5YfH5KmV9TiwJluP64D+iBiKiONAP2eCaEsOiGbW5Cy6zBdJ2l93jF0G8HeAnwH/TdIPJX0j1z5YlpvPk68X5/XLgUN1+QczbXm+H5vekCcihoF3KbY9LSurlAdVzKzBWY4yH+uwdcg84PeBP42IvZK+RnaPS7T64miTPt48LbmFaGZNurhA7CAwGBF78/PjFAHySHaDydejdddfUpd/BXA401e0SG/II2kecAEw1KasUg6IZtYgQgzHnEpH57Li/wKHJH00k9YArwK7gdqobx/wZL7fDWzMkePLKAZPns9u9QlJ1+X9wVvG5KmVdSPwTN5nfBpYK2lJDqaszbRS7jKbWZMuT8z+U+CbkhYAPwH+NUVjbJekTcBbwE0AEXFA0i6KoDkM3BYRI1nOrcBDwCLgqTygGLB5RNIARctwY5Y1JOkuYF9ed2dEDLWrqAOimTXo9pMqEfES0Oo+45qS67cCW1uk7weuapF+kgyoLc5tB7ZXrasDopk18aN7ZmZ4gVgzswZVH8ubbRwQzaxBBAx7gVgzs4K7zGZm+B7i5NI5aor35r8/s3MiHBDNzAoeVDEzoxhUcZfZzAwAMeJRZjOzgu8hmpnhXffMzM6I4j5iL3JANLMmvTrK3PHOqaTtko5KeqUurXQLQTOb2SIHVaocs02Vf6KHaN6pquUWgmY2O0RUO2abjgExIn5AsQptvbItBM1sFohQpWO2Ge89xIYtBCVdXHZhbku4GWAh543z68xsshStv9kX7Ko454MqEbEN2AawWEtnYSPbbPbp1Wk3470rWraFoJnNAt28hyjpTUkvS3pJ0v5MKx2YlXSHpAFJr0taV5d+TZYzIOm+3H2P3KHvsUzfK+nSujx9+R0HJfXRwXgDYtkWgmY2wwVidHROpeMsfDIirq7b1L7lwKykKyh2zbuSYjD3fklzM88DFLffVuZRG+zdBByPiMuBe4F7sqylwBbgWmA1sKXTjJgq024eBZ4FPippMLcNvBv4tKSDwKfz88RJpUd0OBDjPqQoPcx6UVQ8JqBsYHYDsDMiTkXEG8AAsDp7oosj4tncc/nhMXlqZT0OrMnW4zqgPyKGIuI40E/zjJkGHe8hRsTNJadabiFoZjPc2Q2qXFTrBqdtOW4wpkS+p6KF8V/zfNnA7HLgubq8g5l2Ot+PTa/lOZRlDUt6F7iwPr1Fnpb8pIqZNave/DtW1w0u84mIOJxBr1/Sj9tc2yoSR5v08eZpafZNNTezCevmPMSIOJyvR4EnKO7nlQ3MDgKX1GVfARzO9BUt0hvySJoHXEAxd7qsrFIOiGbWIIDRUVU6OpF0vqQP1d4Da4FXKB+Y3Q1szJHjyygGT57P7vUJSdfl/cFbxuSplXUj8EzeZ3waWCtpSQ6mrM20Uu4ym1mjALo3D3EZ8ETOkJkHfCsivitpH7ArB2nfAm4CiIgDknYBrwLDwG0RMZJl3UrxKPEi4Kk8AB4EHpE0QNEy3JhlDUm6C9iX190ZEWOfumvggGhmTbr1nHJE/AT4WIv0dygZmI2IrcDWFun7gatapJ8kA2qLc9uB7VXrO70Cosr/KsXc0lPF+d6cWG92bvTojLPpFRDNbBqYnQs3VOGAaGbN3EI0M6OYmF1hBHk2ckA0sxYcEM3MCu4ym5klB0QzM7o9MXtGmdyAKNCcdnMNy58kjDb5ivPtv/dcmcvouSvcbIrMxg2kqnAL0cyaeZTZzKzQq2sjOyCaWaMuLIc9UzkgmtkY8qCKmdn73EI0M0s9OnlikgOiQG3mx8wrX+NrtFNN27Xw57T/czenV+8gm7XieYhmZmf0ahvBAdHMmvVoQPQmU2ZmyQHRzJooqh2VypLmSvqhpL/Nz0sl9Us6mK9L6q69Q9KApNclratLv0bSy3nuvtx5j9yd77FM3yvp0ro8ffkdByX1UYEDopk1CopH96oc1XwBeK3u8+3AnohYCezJz0i6gmLHvCuB9cD9kmojrQ8Amym2JV2Z5wE2Accj4nLgXuCeLGspsAW4lmIf6C31gbeMA6KZNYuKRweSVgD/FPhGXfIGYEe+3wHcUJe+MyJORcQbwACwOjeyXxwRz+Z+yw+PyVMr63FgTbYe1wH9ETEUEceBfs4E0VIeVDGzJmcxynyRpP11n7dFxLa6z38J/AfgQ3Vpy3LjeSLibUkXZ/py4Lm66wYz7XS+H5tey3MoyxqW9C5wYX16izylOgZESduBfwYcjYirMu3LwL8FfpaXfSkivtOpLADaLv/Vbh5i++Z523mKHVr2vTnjyqyN6gHxWESsanVCUi1uvCDp+gpltfpPMdqkjzdPqSpd5odo3dS8NyKuzqNaMDSzmaE7XeZPAH8s6U1gJ/CHkv47cCS7weTr0bx+ELikLv8K4HCmr2iR3pBH0jzgAmCoTVltdQyIEfGD/AIz6wFVR5g7dasj4o6IWBERl1IMljwTEX8C7AZqo759wJP5fjewMUeOL6MYPHk+u9cnJF2X9wdvGZOnVtaN+R0BPA2slbQkB1PWZlpbE7mH+HlJtwD7gT/LG5dmNhuc2wVi7wZ2SdoEvAXcBBARByTtAl4FhoHbImIk89xK0VtdBDyVB8CDwCOSBigabhuzrCFJdwH78ro7I6Jjw268AfEB4C6KRvNdwFeBf9PqQkmbKYbLWch54/w6M5tM3X50LyK+D3w/378DrCm5biuwtUX6fuCqFuknyYDa4tx2YPvZ1HNc024i4khEjETEKPB1ink+Zddui4hVEbFqvhaO5+vMbLJ1adrNTDOugFi7IZo+C7zSneqY2ZTr0j3EmajKtJtHgesp5hsNUsz+vl7S1RR/I94EPlfly1SU16Y25fG507SbKJ+xgzos/9XOHPXownDW22ZhsKuiY0CMiJtbJD94DupiZtNEr7YD/OiemVnyo3tm1sxdZjMz3h9U6UUOiGbWzAHRzCw5IJqZ5fS4Hh1lntSAGBGMvne69Hy7OYrt5hkCRLu5hh1uiHgbUrM6vodoZlbHAdHMLDkgmpkV3GU2M6txQDQzoxhU8SizmVlyC3GSRPmfHo2Wn4tOK5p76zyzrvE9RDOzmh4NiF7+y8waVd0+oELQlLRQ0vOS/pekA5L+Y6YvldQv6WC+LqnLc4ekAUmvS1pXl36NpJfz3H25Ax+5S99jmb5X0qV1efryOw5K6qMDB0QzayC6uoXAKeAPI+JjwNXAeknXAbcDeyJiJbAnPyPpCoqd866k2A/+fkm159QeoNiwbmUetf3iNwHHI+Jy4F7gnixrKcUK/9dS7Pu0pT7wtuKAaGZNuhUQo/DL/Dg/jwA2ADsyfQdwQ77fAOyMiFMR8QYwAKzOfZwWR8Szue/yw2Py1Mp6HFiTrcd1QH9EDOU2yf2cCaItOSCaWbPqXeaLJO2vOzaPLUrSXEkvAUcpAtReYFluQE++XpyXLwcO1WUfzLTl+X5sekOeiBgG3gUubFNWKQ+qmFmz6oMqxyJiVduiis3mr5b0YeAJSU37K9dpNV8k2qSPN09LbiGaWaNztA1pRPycYrP69cCR2nbG+Xo0LxsELqnLtgI4nOkrWqQ35JE0D7gAGGpTVqnJD4iaU3roveHyY5S2Ry9tpm12znVvlPk3smWIpEXAp4AfA7uB2qhvH/Bkvt8NbMyR48soBk+ez271CUnX5f3BW8bkqZV1I/BM3md8GlgraUkOpqzNtFLuMptZky4+uvcRYEeOFM8BdkXE30p6FtglaRPwFnATQEQckLQLeBUYBm7LLjfArcBDwCLgqTyg2Bb5EUkDFC3DjVnWkKS7gH153Z0RMdSusg6IZtakW0+qRMSPgI+3SH8HWFOSZyuwtUX6fqDp/mNEnCQDaotz24HtVevrgGhmjXr4VpMDopk1c0A0MzvzpEovckA0syYa7c2IOL2W//r1qfJzHUa9evUvmlnX9fA9xI7zECVdIunvJL2Wq1V8IdNLV6sws5ntXEzMngmqTMweBv4sIn4PuA64LVekaLlahZnNAl2amD3TdAyIEfF2RLyY708Ar1E8IF22WoWZzXC92kI8q3uIufDix4Gm1SokXVySZzPFGmYs5LwJVdbMJsksDHZVVA6Ikj4I/DXwxYj4RS5W21FEbAO2ASzW0h79mc1mkOjdXfcqLe4gaT5FMPxmRHw7k8tWqzCzGazLK2bPKFVGmUXx8PRrEfEXdafKVqsws5kuotoxy1TpMn8C+JfAy7nqLcCXgLtpsVpFR+1+xJNt5iF2+vGjTWzvuIepmdWbja2/KjoGxIj4n5TvetxytQozm8Fm6ZSaKvzonpk16dVBFQdEM2vigGhmBtll7s0+swOimTXxoIqZWU2PBsTJ33VvztzSI4aHS49zaTRUepj1mm5OzB7PalmS7pA0IOl1Sevq0q+R9HKeuy/nSJM79D2W6XvzEeNanr78joOS+ujA+zKbWaMINFrtqOCsVsvKcxuBKyn2b74/d+wDeIBiXYSVeazP9E3A8Yi4HLgXuCfLWgpsAa4FVgNbOi1T6IBoZs26tPzXOFbL2gDsjIhTEfEGMACszseDF0fEs7nn8sNj8tTKehxYk63HdUB/RAxFxHGgnzNBtCXfQzSzJmcxqHKRpP11n7flgi7NZVZbLWs58FxdtsFMO53vx6bX8hzKsoYlvQtcWJ/eIk9LDohm1iiA6nuqHIuIVZ0uOovVslqdiDbp483TkrvMZtasiytmn+VqWYPAJXXZVwCHM31Fi/SGPJLmARcAQ23KKuWAaGZNujjKfLarZe0GNubI8WUUgyfPZ/f6hKTrssxbxuSplXUj8EzeZ3waWCtpSQ6mrM20Uu4ym1mTLm5DelarZUXEAUm7gFcpRqhvi4iRzHcr8BCwCHgqDygC7iOSBihahhuzrCFJdwH78ro7I2KoXWUnNyBKaO7c8vPn6HGhHn0KyWx8urjazXhWy4qIrcDWFun7gatapJ+kZPnBiNgObK9aX7cQzaxBMTG7N1sRDohm1syr3ZiZFdxCNDMDr5htZnZG5eeUZx0HRDNr5i7zJJnTZkmtkZHycx306oKWZl3XwxvVu4VoZs3cQjQzS70ZDx0QzayZRnuzz+yAaGaNAk/MNjMDEOGJ2WZm73NANDNLPRoQOy4Q22YbwS9L+qmkl/L4ownXZv6C8qOTNqv6Su0PM6tTu4dY5ZhlqrQQa9sIvijpQ8ALkvrz3L0R8ZVzVz0zmwoeZS6RS3fXdsc6Iam2jaCZzUrhLnMVY7YRBPi8pB9J2t5pA2gzmyGCIiBWOWaZygFx7DaCwAPA7wJXU7Qgv1qSb7Ok/ZL2n46TE6+xmZ17PXoPsVJAbLWNYEQciYiRiBgFvg6sbpU3IrZFxKqIWDVfC7tVbzM7hxRR6ehYTtF7PCrplbq0pZL6JR3M1yV15+6QNCDpdUnr6tKvkfRynrsvd94jd+d7LNP3Zi+2lqcvv+OgpNqufG1VGWVuuY1gbU/V9FnglbF5zWyG6l6X+SFg/Zi024E9EbES2JOfkXQFxY55V2ae+yXVdqV7ANhMsS3pyroyNwHHI+Jy4F7gnixrKbAFuJaisbalym29KqPMZdsI3izpaoo7Dm8Cn+tUkCS0oM0UmtHy5b8++NP32pb9i0vLW58xOv65NaPhrautx0TASHf6wxHxg/pWW9oAXJ/vdwDfB/4803dGxCngjdxWdLWkN4HFEfEsgKSHgRsotiHdAHw5y3oc+M/ZiFsH9Ne2Hc2ZMeuBR9vVt8ooc9k2gt/plNfMZqjqAyYXSdpf93lbRGzrkGdZzl4hIt6WdHGmLweeq7tuMNNO5/ux6bU8h7KsYUnvAhfWp7fIU8pPqphZs+oB8VhErOrSt7ZqeEWb9PHmKeX+oJk1CmA0qh3jc6Q2BpGvRzN9ELik7roVwOFMX9EivSGPpHnABcBQm7LackA0szECYrTaMT67gdqobx/wZF36xhw5voxi8OT57F6fkHRd3h+8ZUyeWlk3As9ERABPA2slLcnBlLWZ1pa7zGbWKOjaoIqkRykGUC6SNEgx8ns3sEvSJuAt4CaAiDggaRfwKsUjw7dFRG2k9VaKEetFFIMpT2X6g8AjOQAzRDFKTUQMSboL2JfX3VkbYGnHAdHMmnXpKZSIuLnk1JqS67cCW1uk7weuapF+kgyoLc5tB7ZXriwOiGbWyix8LK+KyQ+I7VbRaLcWV4d/P6Pzx1edCkWb9ZjZ+ZxyFW4hmlmjoH3DZRZzQDSzZm4hmpkBdO/RvZnGAdHMGgXE+OcYzmgOiGbWbPxPocxoDohm1sz3ECdBBIyUL/HV7l/Cry9uv/Pegl+Unzs17K31zCqL8Cizmdn73EI0MwMIol1PbhZzQDSzRrXlv3qQA6KZNfO0GzOz3JbZLUQzM3JHPbcQzcwAenZQRTGJw+uSfgb8fV3SRcCxSatANdOxTjA96zUd6wTTs16TVaffjojfmEgBkr5LUd8qjkXE2H2XZ6xJDYhNXy7t7+KOXV0xHesE07Ne07FOMD3rNR3rZM28yZSZWXJANDNLUx0Qt03x97cyHesE07Ne07FOMD3rNR3rZGNM6T1EM7PpZKpbiGZm04YDoplZmpKAKGm9pNclDUi6fSrq0IqkNyW9LOklSfunqA7bJR2V9Epd2lJJ/ZIO5uuSaVKvL0v6af5eL0n6o0mu0yWS/k7Sa5IOSPpCpk/p79WmXlP6e1lnk34PUdJc4H8DnwYGgX3AzRHx6qRWpAVJbwKrImLKJvVK+gPgl8DDEXFVpv0nYCgi7s4/IEsi4s+nQb2+DPwyIr4ymXWpq9NHgI9ExIuSPgS8ANwA/Cum8PdqU69/zhT+XtbZVLQQVwMDEfGTiHgP2AlsmIJ6TEsR8QNgaEzyBmBHvt9B8R/XpCqp15SKiLcj4sV8fwJ4DVjOFP9ebepl09xUBMTlwKG6z4NMn/+zBPA9SS9I2jzVlamzLCLehuI/NuDiKa5Pvc9L+lF2qSe9K18j6VLg48BeptHvNaZeME1+L2ttKgJiqw1Opsvcn09ExO8DnwFuy26ilXsA+F3gauBt4KtTUQlJHwT+GvhiRLTZXWdytajXtPi9rNxUBMRB4JK6zyuAw1NQjyYRcThfjwJPUHTvp4MjeV+qdn/q6BTXB4CIOBIRI1Fs4vt1puD3kjSfIuh8MyK+nclT/nu1qtd0+L2svakIiPuAlZIuk7QA2AjsnoJ6NJB0ft4AR9L5wFrglfa5Js1uoC/f9wFPTmFd3lcLOumzTPLvJUnAg8BrEfEXdaem9Pcqq9dU/17W2ZQ8qZLTDf4SmAtsj4itk16JMST9DkWrEIp1Ir81FfWS9ChwPcXyS0eALcDfALuA3wLeAm6KiEkd4Cip1/UU3b8A3gQ+V7t3N0l1+ifA/wBeBmormn6J4n7dlP1ebep1M1P4e1lnfnTPzCz5SRUzs+SAaGaWHBDNzJIDoplZckA0M0sOiGZmyQHRzCz9fzkTtsgObm2fAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "chi2_training=chi2_training[1:,1:]\n",
    "chi2_validation=chi2_validation[1:,1:]\n",
    "kishsize_training=kishsize_training[1:,1:]\n",
    "kishsize_validation=kishsize_validation[1:,1:]\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.flip(chi2_training,axis=0))\n",
    "row,col=np.where(np.flip(chi2_training,axis=0) == np.min(chi2_training))\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.flip(chi2_validation,axis=0))\n",
    "row,col=np.where(np.flip(chi2_validation,axis=0) == np.min(chi2_validation))\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.flip(kishsize_training,axis=0)) \n",
    "row,col=np.where(np.flip(chi2_training,axis=0) == np.min(chi2_training))\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.flip(kishsize_validation,axis=0)) \n",
    "row,col=np.where(np.flip(chi2_validation,axis=0) == np.min(chi2_validation))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac57455",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
